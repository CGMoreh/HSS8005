[
  {
    "objectID": "materials/index.html",
    "href": "materials/index.html",
    "title": "Materials",
    "section": "",
    "text": "Materials for each week are available from the side menu. The table below outlines the weekly topics.\n\n\n\n\n\n\nWeekly topics\n\n\n\n\n\n\n\n\nWeek 1  Gamblers, God, Guinness and peas\n\n\nA brief history of statistics\n\n\n\n\nWeek 2  Revisiting Flatland\n\n\nA review of general linear models\n\n\n\n\nWeek 3  Dear Prudence, Help! I may be cheating with my X\n\n\nInteractions and the logic of causal inference\n\n\n\n\nWeek 4  The Y question\n\n\nGeneralised linear models\n\n\n\n\nWeek 5  Do we live in a simulation?\n\n\nBasic data simulation for statistical inference and power analysis\n\n\n\n\nWeek 6  Challenging hierarchies\n\n\nMultilevel models\n\n\n\n\nWeek 7  The unobserved\n\n\nLatent variables and structural models\n\n\n\n\nWeek 8  Words, words, mere words…\n\n\nText as data\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materials/worksheets/draft-worksheets_w04.html",
    "href": "materials/worksheets/draft-worksheets_w04.html",
    "title": "Week 4 Computer Lab Worksheet",
    "section": "",
    "text": "In this lab you will practice fitting various types of generalised linear models. These models generalise linear regression to situations where the outcome (dependent) variable is not drawn from a normal (Gaussian) distribution. We will look at examples of logit/probit, Poisson, and ordered/unordered categorical (multinomial) models. Given the diversity of models that we aim to cover, we will be using several data sources. Continuing the idea of causal estimation from week 3, we start with data underpinning the article by Ladd and Lenz (2009) and will attempt to replicate a simpler version of their probit model (see their Table 1A). In further exercises we will use data from Wave 5 (2017-2021) of the European Values Study and recoded versions of the LaddLenz dataset to practice ordinal and multinomial regression. Given the wide range of exercises, you will probably need to be selective with what you aim to achieve in class, and which exercises you would leave to complete outside class.\nBy the end of the session, you will:\n\nlearn how to fit logit, probit, Poisson, ordinal and multinomial regression models\ngain experience summarising, visualising and interpreting results from these models\npractice further data manipulation techniques"
  },
  {
    "objectID": "materials/worksheets/draft-worksheets_w04.html#setup",
    "href": "materials/worksheets/draft-worksheets_w04.html#setup",
    "title": "Week 4 Computer Lab Worksheet",
    "section": "Setup",
    "text": "Setup\nIn Week 1 you set up R and RStudio, and an RProject folder (we called it “HSS8005_labs”) with an .R script and a .qmd or .Rmd document in it (we called these “Lab_1”). Ideally, you saved this on a cloud drive so you can access it from any computer (e.g. OneDrive). You will be working in this folder. If it’s missing, complete Task 2 from the Week 1 Lab.\nYou can create a new .R script and .qmd/.Rmd for this week’s work (e.g. “Lab_4”).\nWe can also load the packages that we will be using in this lab. As the number of libraries needed for completing more advanced analyses increases, it’s worth using some method that avoids repetition, such as the p_load() function from pacman:\n\n## First, install {pacman} if not yet installed:\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n## Then use {pacman} to attach packages and if they are not yet installed, install them:\npacman::p_load(tidyverse, sjPlot, sjlabelled, sjmisc,\n               modelsummary, summarytools, gtsummary,\n               marginaleffects)\n\n\n\n\n\n\n\nIf install.packages() throws up an error in Rmd/qmd:\n\n\n\n\n\nIf you are working in Rmarkdown/Quarto and you get an error message that includes the description\n...Error in contrib.url(repos, \"source\") :\n  trying to use CRAN without setting a mirror...\nyou can specify the CRAN mirror to be used by adding\n\noptions(repos = list(CRAN = \"http://cran.rstudio.com/\"))\n\nbefore the call to install.packages()"
  },
  {
    "objectID": "materials/worksheets/draft-worksheets_w04.html#exercise-1-estimating-the-persuasive-power-of-the-news-media",
    "href": "materials/worksheets/draft-worksheets_w04.html#exercise-1-estimating-the-persuasive-power-of-the-news-media",
    "title": "Week 4 Computer Lab Worksheet",
    "section": "Exercise 1: Estimating the persuasive power of the news media",
    "text": "Exercise 1: Estimating the persuasive power of the news media\nIn this exercise we will focus on data from an article by Ladd and Lenz (2009) (follow the doi link in the citation to access the article; you can also download it here). In this article the authors aim to estimate whether (print) media has the power to persuade people to vote differently. In general terms, this is a very interesting question, even though the power of print media has definitely weakened over the past few decades and measuring the effect of alternative media sources would present additional challenges. Nevertheless, the authors attempt to take advantage of a unique natural experiment that arguably facilitates tackling this causal question: between the 1992 and 1997 UK general elections, four newspapers (the Sun, Daily Star, Independent, and Financial Times) changed their editorial stance and tone from supporting the Conservative Party to supporting Tony Blair’s Labour Party. Such radical shifts editorial stance are extremely rare. The data they use come from several waves of the British Election Panel Study from between 1992 and 1997 and include variables on voting behaviour in 1992 and 1997, as well as whether the respondent was a reader of one of the “switching” newspapers. These are the main variables that are useful for tackling the causal effect involved in the research question, but there are several other variable that provide various controls.\nData exploration\nWe can load a version of the dataset from the course website. The dataset is in Stata format (.dta), so we’ll use one of the import functions we’ve used before:\n\n# Let's call the data object \"news\" for simplicity\n\nnews <- sjlabelled::read_stata(\"https://cgmoreh.github.io/HSS8005-data/LaddLenz.dta\")\n\n\n\n\nBecause it’s a Stata dataset, the variables are likely to have useful labels that can provide more information about them. We have already used the sjPlot::view_df() function, which is very useful for this:\n\nview_df(news)\n\nHave a look at the table to get a sense for the data. Table 1S in the Appendix to the article offers more details on the coding and meaning of the variables, which will be very useful later. You can download the Appendix here.\n\nQuestions\n\nWhat does the hhincq92 (“Prior Income”) variable measure, and how are its levels coded?\nWhat might the values coded as “9” in some of the variables mean?\n\n\n\nTo better understand the dataset and check whether any data management tasks are needed before the statistical analysis, let’s learn a few new functions that can come handy. There are various packages that include functions to summarise data, and we will look at three further options: modelsummary, gtsummary and summarytools.\nsummarytools::dfSummary()\nThis is a nice quick function that produces more complex “codeplans” than sjPlot::view_df() for labelled data in a similar HTML format. The easiest way to use it is to combine it with summarytools::view() as part of the same pipeline to get a nicely formatted HTML table in the Viewer pane:\n\nsummarytools::dfSummary(news) |> summarytools::view()\n\ngtsummary::tbl_summary()\nThis is another option that works well with labelled data and produces summaries of both numeric continuous and categorical variables in a publication-ready table style, but it can be very useful for quick descriptive checks. It’s a little bit slow:\n\ngtsummary::tbl_summary(news)\n\nmodelsummary::datasummary_skim()\nThis function doesn’t show variable labels and by default only summarises “numeric” variables; categorical variables can be tabulated separately by adding the argument type = \"categorical\". It works on our dataset because all the variables are currently recognised as numeric, but it’s not the most efficient for labelled data. We’ll look at it because the {modelsummary} package contains a number of other extremely useful functions that produce flexible tables, which we will use later:\n\nmodelsummary::datasummary_skim(news)\n\n\n\nQuestions\n\nWhat else have we learnt about the data?\nAre there any data transformation tasks necessary before we use the data for statistical modelling?\n\n\nData wrangling\nIt really appears that the values coded as 9 across several variables are in fact “missing” values. Instead of excluding them from the statistical analysis by setting them as NA, we will keep them, just as the authors of the original study have done. But we’ll relabel the categorical (factor) variables before further analysis.\nThere are some other strange inconsistencies that we should take care of. Let’s take them step-by step in the code-chunk below using some convenience functions from sjlabelled and sjmisc (note that everything could be done with some extra coding using core tidyverse packages):\n\nnews <- news |> \n  \n## wkclass should be an indicator dummy, but kept as numeric;\n## `dicho` function by default creates a new variable with \"_d\" as suffix in the name;\n## setting `suffix = \"\"` overwrites the original variable\n  sjmisc::dicho(wkclass, dich.by = 0.5, as.num = TRUE, suffix = \"\") |> \n  \n## categories (levels) can be labelled\n  sjlabelled::set_labels(know_3, labels = c(\"low\", \n                                           \"medium\", \n                                           \"high\")) |> \n  sjlabelled::set_labels(copemg92, labels = c(\"Mortgage Very Difficult\" = 1, \n                                              \"Mortgage a Bit Difficult\" = 0.5, \n                                              \"Not Really Difficult or No Mortgage\" = 0,\n                                              \"Not answered\" = 9)) |> \n  sjlabelled::set_labels(hedqul92, labels = c(\"Less than O level (or foreign qual)\" = 0,\n                                              \"O Level or Equivalent\" = .25,\n                                              \"A Level or Equivalent\" = .5,\n                                              \"Some Higher Education\" = .75,\n                                              \"College Degree\" = 1)) |> \n  sjlabelled::set_labels(hhincq92, labels = c(\"5999 or Less\", \n                                              \"6000-11,999\",\n                                              \"12,000-19,999\",\n                                              \"20,000 or More\",\n                                              \"Not answered\")) |> \n  sjlabelled::set_labels(ragect92, labels = c(\"18-24\", \n                                              \"25-34\",\n                                              \"35-44\", \n                                              \"45-54\", \n                                              \"55-59\",\n                                              \"60-64\", \n                                              \"65+\", \n                                              \"Not Given\")) |> \n\n## some variables should be categorical (factor)\n  \n  ### first, change to character type to overwrite the fractional numeric codes with the labels\n  sjlabelled::as_character(know_3, hedqul92, hhincq92, ragect92) |> \n  \n  ### then, change to factors; labels will show, levels are renumbered starting from 1\n  sjlabelled::as_factor(know_3, hedqul92, hhincq92, ragect92) |> \n\n##### instead of the two commands above, changing to `sjlabelled::as_label()` has the same effect\n##### note also that we did not set \"copemg92\" as categorical, just because the authors will treat is as numeric in their model, even if it doesn't make much sense, especially because of the \"Not answered\" category\n\n## Finally, some changes will make it easier to read the model as fit by the authors:\n\n  ### will change the label associated with the `tolabor` variable (the \"treatment\" variable)\n  sjlabelled::var_labels(tolabor = \"Treatment (read switching paper)\")\n\nWe can check some frequency tabulations to see the outcome:\n\n# Five frequency tables\nnews |> sjmisc::frq(know_3, copemg92, hedqul92, hhincq92, ragect92)\n\nOr we can check a whole summary table of the data frame again, which now looks like this:\n\ngtsummary::tbl_summary(news)\n\n\n\n\n\n\n\nThis is what your table should look like:\n\n\n\n\n\n\n\n\n\n\n Characteristic \n    N = 1,593 \n  \n\n\n outcome: voted labor in 1997 \n    718 (45%) \n  \n\n Treatment (read switching paper) \n    211 (13%) \n  \n\n Prior Conservative Identification \n    666 (42%) \n  \n\n Prior Labour Identification \n    506 (32%) \n  \n\n Prior Liberal Identification \n    241 (15%) \n  \n\n White \n    1,557 (98%) \n  \n\n Working-Class \n    955 (60%) \n  \n\n Parents Voted Labour \n    581 (36%) \n  \n\n Prior Ideological Moderation \n    0.69 (0.49, 0.83) \n  \n\n Prior Labour Vote \n    528 (33%) \n  \n\n Prior Conservative Vote \n    640 (40%) \n  \n\n Prior Liberal Vote \n    293 (18%) \n  \n\n Prior Labour Party Support \n    0.50 (0.25, 0.75) \n  \n\n Prior Conservative Party Support \n    0.50 (0.25, 0.75) \n  \n\n Prior Political Knowledge \n     \n  \n\n high \n    744 (47%) \n  \n\n low \n    252 (16%) \n  \n\n medium \n    597 (37%) \n  \n\n Prior Television Viewer \n    446 (28%) \n  \n\n Prior Daily Newspaper Reader \n    1,111 (70%) \n  \n\n Prior Ideology \n    0.55 (0.41, 0.68) \n  \n\n Authoritarianism \n    0.56 (0.48, 0.64) \n  \n\n Prior Trade Union Member \n    378 (24%) \n  \n\n Prior Coping Mortgage \n     \n  \n\n 0 \n    272 (17%) \n  \n\n 0.5 \n    511 (32%) \n  \n\n 1 \n    807 (51%) \n  \n\n 9 \n    3 (0.2%) \n  \n\n Prior Education \n     \n  \n\n A Level or Equivalent \n    187 (12%) \n  \n\n College Degree \n    636 (40%) \n  \n\n Less than O level (or foreign qual) \n    168 (11%) \n  \n\n O Level or Equivalent \n    271 (17%) \n  \n\n Some Higher Education \n    331 (21%) \n  \n\n Prior Income \n     \n  \n\n 12,000-19,999 \n    377 (24%) \n  \n\n 20,000 or More \n    528 (33%) \n  \n\n 5999 or Less \n    245 (15%) \n  \n\n 6000-11,999 \n    313 (20%) \n  \n\n Not answered \n    130 (8.2%) \n  \n\n Prior Age \n     \n  \n\n 18-24 \n    103 (6.5%) \n  \n\n 25-34 \n    289 (18%) \n  \n\n 35-44 \n    347 (22%) \n  \n\n 45-54 \n    344 (22%) \n  \n\n 55-59 \n    128 (8.0%) \n  \n\n 60-64 \n    118 (7.4%) \n  \n\n 65+ \n    243 (15%) \n  \n\n Not Given \n    21 (1.3%) \n  \n\n Male \n    864 (54%) \n  \n\n North West \n    143 (9.0%) \n  \n\n Yorks \n    120 (7.5%) \n  \n\n West Midlands \n    129 (8.1%) \n  \n\n East Midlands \n    109 (6.8%) \n  \n\n East Anglia \n    49 (3.1%) \n  \n\n SW England \n    126 (7.9%) \n  \n\n SE England \n    272 (17%) \n  \n\n Greater London \n    115 (7.2%) \n  \n\n Wales \n    59 (3.7%) \n  \n\n Scotland \n    396 (25%) \n  \n\n Profession: Large Employer \n    242 (15%) \n  \n\n Profession: Small Employer \n    73 (4.6%) \n  \n\n Profession: Self Employed \n    628 (39%) \n  \n\n Profession: Employee \n    64 (4.0%) \n  \n\n Profession: Temporary Worker \n    480 (30%) \n  \n\n Profession: Junior \n    77 (4.8%) \n  \n\n\n1 n (%); Median (IQR)\n\n\n\n\n\n\nComparing proportions\nThe aim of Ladd and Lenz (2009) is to estimate the effect of “reading a switching newspaper” on respondents’ voting behaviour change between the 1992 and 1997 elections. In terms of our variables in the dataset, they aim to estimate vote_l_97 (Voted Labour in 1997) from vote_l_92 (Prior Labour vote in 1992) as moderated by tolabor (treatment: indicator of whether reading a switching newspaper). All three variables are binary indicator variables.\nWe have what is called panel data, consisting of measurements on the same individuals at two different time points (1992 and 1997), which allows us to think in causal terms. But the question could be first broken down into two smaller questions exploring:\n\nthe average treatment effect of tolabour in a cross-sectional design (oblivious of prior vote)\na before/after comparison of the treated group, comparing their average vote in 1997 to their average vote in 1992\na differences-in-differences comparison of the average changes over time in the treatment group and average changes over time in the control group.\n\nOverall mean vote\nWhat is the overall proportion of those voting Labour in the 1997 elections in the sample?\n\nmean(news$vote_l_97)\n\n[1] 0.4507219\n\n\nAs with all proportions, this can be read as a percentage if multiplied by 100:\n\nmean(news$vote_l_97) * 100\n\n[1] 45.07219\n\n\nConditional mean vote\nWhat about the proportion of Labour voters among those who read/not read papers that shifted their editorial support?\n\n# We can first break down the dataset into two:\nreader <- news |>  filter(tolabor == 1) \nnot_reader <- news |>  filter(tolabor == 0) \n\n# Then calculate means within each:\nmean_reader_97 <- mean(reader$vote_l_97)\nmean_not_reader_97 <- mean(not_reader$vote_l_97)\n\n# With the result:\nmean_reader_97\nmean_not_reader_97\n\n[1] 0.5829384\n[1] 0.4305355\n\n\nAverage Treatment Effect\nThe average treatment effect would be the difference between the two groups:\n\nATE <- mean_reader_97 - mean_not_reader_97\n\nATE\n\n[1] 0.1524029\n\n\nBefore/After\n\nmean_reader_92 <- mean(reader$vote_l_92)\nmean_not_reader_92 <- mean(not_reader$vote_l_92)\n\nBA_reader <- mean_reader_97 - mean_reader_92\nBA_reader\n\nBA_not_reader <- mean_not_reader_97 - mean_not_reader_92\nBA_not_reader\n\n[1] 0.1943128\n[1] 0.1078148\n\n\nDifferences-in-Differences\n\nDD <- BA_reader - BA_not_reader\n\nDD\n\n[1] 0.08649803\n\n\n\nQuestions\n\nWhat have we learnt from these various comparisons of proportions?\n\n\nLinear probability model\nThe comparison of proportions that we calculated earlier rely on comparing average changes, so we could obtain the results using ordinary least squares linear regression. For example, we can check what the overall mean vote for Labour in 1997 was in the sample, and the average treatment effect we calculated earlier:\n\n## just the mean of Labour vote in 1997\nmean_l_97 <- lm(vote_l_97 ~ 1, data = news)\ncoefficients(mean_l_97)\n\n(Intercept) \n  0.4507219 \n\n## ATE\nATE_reg <- lm(vote_l_97 ~ tolabor, data = news)\ncoefficients(ATE_reg)\n\n(Intercept)     tolabor \n  0.4305355   0.1524029 \n\n\nThis ATE_reg model is a first step towards fitting the model presented by the authors in Table 1A. They report there on results from a probit regression, but we can start by building a linear regression model that we are familiar with (i.e. we can fit a “linear probability model”):\n\nm0_lpm <- lm(vote_l_97 ~ tolabor + vote_l_92, data = news)\nsummary(m0_lpm)\n\n\nCall:\nlm(formula = vote_l_97 ~ tolabor + vote_l_92, data = news)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.9981 -0.2114 -0.2114  0.1095  0.7886 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.21137    0.01208  17.495  < 2e-16 ***\ntolabor      0.10765    0.02800   3.844 0.000126 ***\nvote_l_92    0.67910    0.02016  33.678  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3784 on 1590 degrees of freedom\nMultiple R-squared:  0.4226,    Adjusted R-squared:  0.4219 \nF-statistic: 581.9 on 2 and 1590 DF,  p-value: < 2.2e-16\n\n\n\nQuestions\nWhat does this simple model tell us?\n\nWhat about if we also include the interaction effect between the two predictors?\n\nm0_lpm_int <- lm(vote_l_97 ~ tolabor * vote_l_92, data = news)\nsummary(m0_lpm_int)\n\n\nCall:\nlm(formula = vote_l_97 ~ tolabor * vote_l_92, data = news)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.92683 -0.20513 -0.20513  0.09641  0.79487 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        0.20513    0.01235  16.607  < 2e-16 ***\ntolabor            0.15921    0.03549   4.486 7.77e-06 ***\nvote_l_92          0.69846    0.02174  32.124  < 2e-16 ***\ntolabor:vote_l_92 -0.13597    0.05763  -2.359   0.0184 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3779 on 1589 degrees of freedom\nMultiple R-squared:  0.4247,    Adjusted R-squared:  0.4236 \nF-statistic: 390.9 on 3 and 1589 DF,  p-value: < 2.2e-16\n\n\n\nQuestion: How do we interpret the coefficients on this simple interaction model?\nIf the interpretation of the interaction model proves difficult (as it should), maybe it’s better to visualise the model by plotting the coefficients. We can do that using the sjPlot::plot_model() function:\n\nsjPlot::plot_model(m0_lpm_int, type = \"pred\", terms = c(\"tolabor\", \"vote_l_92\"))\n\n\n\n\nTo make the meaning of the plot even more straightforward for our interpretative purposes, we can make some changes to the y-axis to display vertical lines at the probability-levels that we got from the model coefficients, and label them with the name of the regression terms. Check the code below against the information from the model summary:\n\nsjPlot::plot_model(m0_lpm_int, type = \"pred\", terms = c(\"tolabor\", \"vote_l_92\")) + \n  scale_y_continuous(breaks = c(0.20513, \n                                0.20513 + 0.15921, \n                                0.20513 + 0.69846, \n                                0.20513 + 0.15921 + 0.69846-0.13597),\n                     labels = c(\"Intercept\",\n                                \"tolabor\",\n                                \"vote_l_92\",\n                                \"tolabor:vote_l_92\"))\n\n\n\n\n\nThe model we are interested in reproducing is that from the first column of Table 1A, and that model does not include any interaction terms, only main effects. We will leave out the interaction, bu instead let’s include all the predictors (independent variables) that were included in the original article. Since all the variables in the dataset are included in that model, we can take a shortcut from having to type out all the additive variable names by using the . identifier as a shorthand for “all the variables in the dataset not already mentioned in the regression formula”. This could then be combined with “-” to exclude some variables that we do not want included. In our case, we want to regress the 1997 vote for Labour on all the other variables in the dataset:\n\nm1_lpm <- lm(vote_l_97 ~ ., data = news)\n\nWe will be comparing the results from this model with those from other models, so instead of checking the model with the summary() function, let’s use the modelsummary() function from the modelsummary package. The function takes a list() object as argument, and the list can include several models to be tabulated side-by-side. For example, let’s include in the summary table three of the models that we built so far: mean_l_97, m0_lpm and m1_lpm. We can either build the list() object first and pass the object to modelsummary(), or we can build the list as part of the call to the latter:\n\nmodelsummary::modelsummary(list(mean_l_97, m0_lpm, m1_lpm))\n\n\n\n\n\n\n\nThis is what the modelsummary table should look like:\n\n\n\n\n\n\n\n\n\n\n   \n     (1) \n      (2) \n      (3) \n  \n\n\n (Intercept) \n    0.451 \n    0.211 \n    0.485 \n  \n\n  \n    (0.012) \n    (0.012) \n    (0.163) \n  \n\n tolabor \n     \n    0.108 \n    0.105 \n  \n\n  \n     \n    (0.028) \n    (0.028) \n  \n\n vote_l_92 \n     \n    0.679 \n    0.280 \n  \n\n  \n     \n    (0.020) \n    (0.046) \n  \n\n conservative \n     \n     \n    −0.003 \n  \n\n  \n     \n     \n    (0.043) \n  \n\n labor \n     \n     \n    0.156 \n  \n\n  \n     \n     \n    (0.042) \n  \n\n liberal \n     \n     \n    0.083 \n  \n\n  \n     \n     \n    (0.044) \n  \n\n white \n     \n     \n    −0.193 \n  \n\n  \n     \n     \n    (0.063) \n  \n\n wkclass \n     \n     \n    0.041 \n  \n\n  \n     \n     \n    (0.022) \n  \n\n parent_labor \n     \n     \n    0.032 \n  \n\n  \n     \n     \n    (0.021) \n  \n\n f_ideo92 \n     \n     \n    0.010 \n  \n\n  \n     \n     \n    (0.080) \n  \n\n vote_c_92 \n     \n     \n    −0.079 \n  \n\n  \n     \n     \n    (0.048) \n  \n\n vote_lib_92 \n     \n     \n    −0.076 \n  \n\n  \n     \n     \n    (0.047) \n  \n\n labfel92 \n     \n     \n    0.224 \n  \n\n  \n     \n     \n    (0.054) \n  \n\n confel92 \n     \n     \n    −0.059 \n  \n\n  \n     \n     \n    (0.052) \n  \n\n know_3low \n     \n     \n    0.085 \n  \n\n  \n     \n     \n    (0.030) \n  \n\n know_3medium \n     \n     \n    0.026 \n  \n\n  \n     \n     \n    (0.022) \n  \n\n TVnewseither \n     \n     \n    0.024 \n  \n\n  \n     \n     \n    (0.021) \n  \n\n read_paper \n     \n     \n    −0.030 \n  \n\n  \n     \n     \n    (0.021) \n  \n\n ideo92 \n     \n     \n    0.134 \n  \n\n  \n     \n     \n    (0.105) \n  \n\n auth92 \n     \n     \n    −0.002 \n  \n\n  \n     \n     \n    (0.077) \n  \n\n tusa92 \n     \n     \n    0.007 \n  \n\n  \n     \n     \n    (0.023) \n  \n\n copemg92 \n     \n     \n    −0.051 \n  \n\n  \n     \n     \n    (0.019) \n  \n\n hedqul92College Degree \n     \n     \n    −0.006 \n  \n\n  \n     \n     \n    (0.034) \n  \n\n hedqul92Less than O level (or foreign qual) \n     \n     \n    −0.028 \n  \n\n  \n     \n     \n    (0.042) \n  \n\n hedqul92O Level or Equivalent \n     \n     \n    −0.003 \n  \n\n  \n     \n     \n    (0.035) \n  \n\n hedqul92Some Higher Education \n     \n     \n    −0.035 \n  \n\n  \n     \n     \n    (0.034) \n  \n\n hhincq9220,000 or More \n     \n     \n    −0.001 \n  \n\n  \n     \n     \n    (0.026) \n  \n\n hhincq925999 or Less \n     \n     \n    0.001 \n  \n\n  \n     \n     \n    (0.033) \n  \n\n hhincq926000-11,999 \n     \n     \n    0.065 \n  \n\n  \n     \n     \n    (0.029) \n  \n\n hhincq92Not answered \n     \n     \n    0.003 \n  \n\n  \n     \n     \n    (0.039) \n  \n\n ragect9225-34 \n     \n     \n    −0.103 \n  \n\n  \n     \n     \n    (0.045) \n  \n\n ragect9235-44 \n     \n     \n    −0.068 \n  \n\n  \n     \n     \n    (0.045) \n  \n\n ragect9245-54 \n     \n     \n    −0.102 \n  \n\n  \n     \n     \n    (0.046) \n  \n\n ragect9255-59 \n     \n     \n    −0.155 \n  \n\n  \n     \n     \n    (0.053) \n  \n\n ragect9260-64 \n     \n     \n    −0.082 \n  \n\n  \n     \n     \n    (0.054) \n  \n\n ragect9265+ \n     \n     \n    −0.113 \n  \n\n  \n     \n     \n    (0.050) \n  \n\n ragect92Not Given \n     \n     \n    −0.168 \n  \n\n  \n     \n     \n    (0.088) \n  \n\n rsex92 \n     \n     \n    −0.026 \n  \n\n  \n     \n     \n    (0.022) \n  \n\n region2 \n     \n     \n    0.020 \n  \n\n  \n     \n     \n    (0.051) \n  \n\n region3 \n     \n     \n    −0.029 \n  \n\n  \n     \n     \n    (0.053) \n  \n\n region4 \n     \n     \n    −0.043 \n  \n\n  \n     \n     \n    (0.053) \n  \n\n region5 \n     \n     \n    0.021 \n  \n\n  \n     \n     \n    (0.054) \n  \n\n region6 \n     \n     \n    0.069 \n  \n\n  \n     \n     \n    (0.066) \n  \n\n region7 \n     \n     \n    −0.077 \n  \n\n  \n     \n     \n    (0.053) \n  \n\n region8 \n     \n     \n    −0.029 \n  \n\n  \n     \n     \n    (0.048) \n  \n\n region9 \n     \n     \n    −0.027 \n  \n\n  \n     \n     \n    (0.055) \n  \n\n region10 \n     \n     \n    −0.025 \n  \n\n  \n     \n     \n    (0.063) \n  \n\n region11 \n     \n     \n    −0.028 \n  \n\n  \n     \n     \n    (0.046) \n  \n\n occupation2 \n     \n     \n    0.003 \n  \n\n  \n     \n     \n    (0.077) \n  \n\n occupation3 \n     \n     \n    −0.024 \n  \n\n  \n     \n     \n    (0.086) \n  \n\n occupation4 \n     \n     \n    0.007 \n  \n\n  \n     \n     \n    (0.074) \n  \n\n occupation5 \n     \n     \n    0.037 \n  \n\n  \n     \n     \n    (0.084) \n  \n\n occupation6 \n     \n     \n    0.002 \n  \n\n  \n     \n     \n    (0.075) \n  \n\n occupation7 \n     \n     \n    −0.110 \n  \n\n  \n     \n     \n    (0.084) \n  \n\n Num.Obs. \n    1593 \n    1593 \n    1593 \n  \n\n R2 \n    0.000 \n    0.423 \n    0.512 \n  \n\n R2 Adj. \n    0.000 \n    0.422 \n    0.495 \n  \n\n AIC \n    2300.8 \n    1429.8 \n    1265.2 \n  \n\n BIC \n    2311.6 \n    1451.3 \n    1560.8 \n  \n\n Log.Lik. \n    −1148.411 \n    −710.907 \n    −577.622 \n  \n\n F \n     \n    581.949 \n    30.417 \n  \n\n RMSE \n    0.50 \n    0.38 \n    0.35 \n  \n\n\n\n\n\n\n\n\nQuestions\n\nHow would you interpret the main variables interest (reading a switching newspaper, and having voted Labour in 1992) in the context of this larger model?\nLook at a few other explanatory variables and briefly interpret the meaning of their coefficients.\n\n\nLogit and Probit\nWhile a linear probability model can be a quick way to check relationships in the data, the linear model function is not appropriate for modelling binary outcomes. One reason is that predictions from the linear model can fall outside the 0-1 probability boundary, which is meaningless (we’ll look at what this means, visually, below).\nTwo models are more appropriate in such contexts: logistic regression (or logit model) and probit models. The authors of the paper use a probit model, and we’ll fit both a probit and a logit so we can compare their results. In R we can fit these types of generalised linear models using the glm() function by specifying a family of distributions and the linear link to be used. Both logit and probit are part of the broader binomial family, and the default link function for this family in glm() is “logit”, so we don’t need to specify that information when fitting a logistic model:\n\n# A \"probit\" model that reproduces Table 1A results\nm1_probit <- glm(vote_l_97 ~ ., family = binomial(link = \"probit\"), data = news)\n\n# A \"logit\" model alternative\nm1_logit <- glm(vote_l_97 ~ ., family = binomial, data = news)\n\nBefore examining the models more closely, let’s visualise predictions from the linear probability, probit and logit model to demonstrate the prediction boundary problem posed by the linear probability model. The three graphs below plot the estimated probabilities for voting Labour in 1997 (vote_l_97) based on the respondents’ “leftist” ideological orientation in 1992 (ideo92) alongside the model-specific regression line (the reason for choosing the ideo92 variable is simply that it’s a numeric variable that is easier to visualise here). The code to produce the plots is not the focus here, but you can unfold the code command to check it if interested:\n\nCode# Extract predicted values as data-frames using the marginaleffects::predictions function\nlpm_effects <- marginaleffects::predictions(m1_lpm)\nlogit_effects <- marginaleffects::predictions(m1_logit)\nprobit_effects <- marginaleffects::predictions(m1_probit)\n\n# A package to combine plots together\nlibrary(patchwork)\n\n# lpm\nplot1 <- lpm_effects |> \n  ggplot(aes(\n    y = estimate, \n    x = ideo92)) +\n  geom_point(alpha = 0.1) +\n  stat_smooth(method=\"lm\", color=\"red\", se=FALSE) +\n  labs(\n    x = \"\",\n    y = \"Estimated probability of voting Labour in 1997\"\n  ) +\n  ylim(-0.25, 1.25) +\n  ggtitle(\"Linear probability model\")\n\n# probit\nplot2 <- probit_effects |> \n  ggplot(aes(\n  y = estimate, \n  x = ideo92)) +\n  geom_point(alpha = 0.1) +\n  stat_smooth(method=\"glm\", color=\"blue\", linetype=1, se=FALSE,\n                method.args = list(family=binomial)) +\n  stat_smooth(method=\"lm\", color=\"red\", se=FALSE) +\n    labs(\n    x = \"Leftist political ideology (in 1992)\",\n    y = \"\"\n  ) +\n  ylim(-0.25, 1.25) +\n  ggtitle(\"Probit model\")\n\n# logit\nplot3 <- logit_effects |> \n  ggplot(aes(\n  y = estimate, \n  x = ideo92)) +\n  geom_point(alpha = 0.1) +\n  stat_smooth(method=\"glm\", color=\"blue\", linetype=1, se=FALSE,\n                method.args = list(family=binomial)) +\n  stat_smooth(method=\"lm\", color=\"red\", se=FALSE) +\n    labs(\n    x = \"\",\n    y = \"\"\n  ) +\n  ylim(-0.25, 1.25) +\n  ggtitle(\"Logit model\")\n\n# Combine the three plots\nplot1 + plot2 + plot3\n\n\n\n\nWe can see from the plots that the predictions regression curve from the probit and logit models are nearly identical and are both constrained between the probability limits of 0 and 1, whereas predictions from the linear model can fall outside these limits, even though to speak of probabilities below 0 and above 1 is meaningless, so our estimates are biased. The graphs highlight well the difference between logit/probit and linear regression.\nWe can now compare our three models in more detail using the modelsummary::modelsummary() function. This time, we will first make a list() object in which we give more meaningful titles to our models, and add a further specification to the modelsummary command to request that the coefficients be renamed using their variable labels (which we conveniently already have in this dataset, as we imported it from Stata format):\n\nmodels <- list(\"OLS\" = m1_lpm,\n               \"Probit\" = m1_probit,\n               \"Logit\" = m1_logit)\nmodelsummary::modelsummary(models, coef_rename = TRUE)\n\n\n\n\n\n\n\nThis is what the table should look like:\n\n\n\n\n\n\n\n\n\n\n   \n    OLS \n    Probit \n    Logit \n  \n\n\n (Intercept) \n    0.485 \n    −0.209 \n    −0.592 \n  \n\n  \n    (0.163) \n    (0.845) \n    (1.585) \n  \n\n Treatment (read switching paper) \n    0.105 \n    0.484 \n    0.840 \n  \n\n  \n    (0.028) \n    (0.127) \n    (0.225) \n  \n\n Prior Conservative Identification \n    −0.003 \n    0.039 \n    0.076 \n  \n\n  \n    (0.043) \n    (0.182) \n    (0.320) \n  \n\n Prior Labour Identification \n    0.156 \n    0.569 \n    1.016 \n  \n\n  \n    (0.042) \n    (0.178) \n    (0.313) \n  \n\n Prior Liberal Identification \n    0.083 \n    0.368 \n    0.657 \n  \n\n  \n    (0.044) \n    (0.181) \n    (0.316) \n  \n\n White \n    −0.193 \n    −0.835 \n    −1.653 \n  \n\n  \n    (0.063) \n    (0.319) \n    (0.567) \n  \n\n Working-Class \n    0.041 \n    0.160 \n    0.300 \n  \n\n  \n    (0.022) \n    (0.097) \n    (0.173) \n  \n\n Parents Voted Labour \n    0.032 \n    0.121 \n    0.238 \n  \n\n  \n    (0.021) \n    (0.094) \n    (0.168) \n  \n\n Prior Ideological Moderation \n    0.010 \n    0.526 \n    0.985 \n  \n\n  \n    (0.080) \n    (0.452) \n    (0.873) \n  \n\n Prior Labour Vote \n    0.280 \n    0.879 \n    1.496 \n  \n\n  \n    (0.046) \n    (0.188) \n    (0.330) \n  \n\n Prior Conservative Vote \n    −0.079 \n    −0.251 \n    −0.436 \n  \n\n  \n    (0.048) \n    (0.202) \n    (0.353) \n  \n\n Prior Liberal Vote \n    −0.076 \n    −0.273 \n    −0.502 \n  \n\n  \n    (0.047) \n    (0.190) \n    (0.329) \n  \n\n Prior Labour Party Support \n    0.224 \n    0.878 \n    1.612 \n  \n\n  \n    (0.054) \n    (0.238) \n    (0.423) \n  \n\n Prior Conservative Party Support \n    −0.059 \n    −0.334 \n    −0.455 \n  \n\n  \n    (0.052) \n    (0.233) \n    (0.417) \n  \n\n Prior Political Knowledge [low] \n    0.085 \n    0.367 \n    0.710 \n  \n\n  \n    (0.030) \n    (0.136) \n    (0.244) \n  \n\n Prior Political Knowledge [medium] \n    0.026 \n    0.112 \n    0.233 \n  \n\n  \n    (0.022) \n    (0.101) \n    (0.183) \n  \n\n Prior Television Viewer \n    0.024 \n    0.141 \n    0.266 \n  \n\n  \n    (0.021) \n    (0.096) \n    (0.174) \n  \n\n Prior Daily Newspaper Reader \n    −0.030 \n    −0.178 \n    −0.314 \n  \n\n  \n    (0.021) \n    (0.096) \n    (0.173) \n  \n\n Prior Ideology \n    0.134 \n    1.076 \n    2.044 \n  \n\n  \n    (0.105) \n    (0.599) \n    (1.170) \n  \n\n Authoritarianism \n    −0.002 \n    −0.157 \n    −0.077 \n  \n\n  \n    (0.077) \n    (0.360) \n    (0.647) \n  \n\n Prior Trade Union Member \n    0.007 \n    0.051 \n    0.088 \n  \n\n  \n    (0.023) \n    (0.104) \n    (0.188) \n  \n\n Prior Coping Mortgage \n    −0.051 \n    −0.202 \n    −0.364 \n  \n\n  \n    (0.019) \n    (0.087) \n    (0.154) \n  \n\n Prior Education [College Degree] \n    −0.006 \n    −0.016 \n    0.038 \n  \n\n  \n    (0.034) \n    (0.157) \n    (0.282) \n  \n\n Prior Education [Less than O level (or foreign qual)] \n    −0.028 \n    −0.093 \n    −0.119 \n  \n\n  \n    (0.042) \n    (0.194) \n    (0.348) \n  \n\n Prior Education [O Level or Equivalent] \n    −0.003 \n    0.019 \n    0.049 \n  \n\n  \n    (0.035) \n    (0.160) \n    (0.286) \n  \n\n Prior Education [Some Higher Education] \n    −0.035 \n    −0.133 \n    −0.233 \n  \n\n  \n    (0.034) \n    (0.155) \n    (0.279) \n  \n\n Prior Income [20,000 or More] \n    −0.001 \n    0.019 \n    0.019 \n  \n\n  \n    (0.026) \n    (0.117) \n    (0.211) \n  \n\n Prior Income [5999 or Less] \n    0.001 \n    0.065 \n    0.041 \n  \n\n  \n    (0.033) \n    (0.153) \n    (0.277) \n  \n\n Prior Income [6000-11,999] \n    0.065 \n    0.356 \n    0.611 \n  \n\n  \n    (0.029) \n    (0.132) \n    (0.235) \n  \n\n Prior Income [Not answered] \n    0.003 \n    0.007 \n    0.072 \n  \n\n  \n    (0.039) \n    (0.177) \n    (0.315) \n  \n\n Prior Age [25-34] \n    −0.103 \n    −0.416 \n    −0.701 \n  \n\n  \n    (0.045) \n    (0.199) \n    (0.349) \n  \n\n Prior Age [35-44] \n    −0.068 \n    −0.274 \n    −0.456 \n  \n\n  \n    (0.045) \n    (0.198) \n    (0.348) \n  \n\n Prior Age [45-54] \n    −0.102 \n    −0.424 \n    −0.764 \n  \n\n  \n    (0.046) \n    (0.206) \n    (0.364) \n  \n\n Prior Age [55-59] \n    −0.155 \n    −0.743 \n    −1.283 \n  \n\n  \n    (0.053) \n    (0.243) \n    (0.435) \n  \n\n Prior Age [60-64] \n    −0.082 \n    −0.351 \n    −0.505 \n  \n\n  \n    (0.054) \n    (0.247) \n    (0.438) \n  \n\n Prior Age [65+] \n    −0.113 \n    −0.544 \n    −0.904 \n  \n\n  \n    (0.050) \n    (0.231) \n    (0.410) \n  \n\n Prior Age [Not Given] \n    −0.168 \n    −0.718 \n    −1.273 \n  \n\n  \n    (0.088) \n    (0.422) \n    (0.779) \n  \n\n Male \n    −0.026 \n    −0.130 \n    −0.253 \n  \n\n  \n    (0.022) \n    (0.101) \n    (0.183) \n  \n\n North West \n    0.020 \n    0.054 \n    0.072 \n  \n\n  \n    (0.051) \n    (0.250) \n    (0.451) \n  \n\n Yorks \n    −0.029 \n    −0.147 \n    −0.141 \n  \n\n  \n    (0.053) \n    (0.260) \n    (0.472) \n  \n\n West Midlands \n    −0.043 \n    −0.215 \n    −0.359 \n  \n\n  \n    (0.053) \n    (0.255) \n    (0.463) \n  \n\n East Midlands \n    0.021 \n    0.057 \n    0.063 \n  \n\n  \n    (0.054) \n    (0.260) \n    (0.470) \n  \n\n East Anglia \n    0.069 \n    0.305 \n    0.498 \n  \n\n  \n    (0.066) \n    (0.310) \n    (0.553) \n  \n\n SW England \n    −0.077 \n    −0.390 \n    −0.712 \n  \n\n  \n    (0.053) \n    (0.260) \n    (0.475) \n  \n\n SE England \n    −0.029 \n    −0.153 \n    −0.226 \n  \n\n  \n    (0.048) \n    (0.234) \n    (0.426) \n  \n\n Greater London \n    −0.027 \n    −0.194 \n    −0.260 \n  \n\n  \n    (0.055) \n    (0.269) \n    (0.488) \n  \n\n Wales \n    −0.025 \n    −0.239 \n    −0.308 \n  \n\n  \n    (0.063) \n    (0.299) \n    (0.543) \n  \n\n Scotland \n    −0.028 \n    −0.177 \n    −0.267 \n  \n\n  \n    (0.046) \n    (0.227) \n    (0.412) \n  \n\n Profession: Large Employer \n    0.003 \n    −0.078 \n    −0.079 \n  \n\n  \n    (0.077) \n    (0.368) \n    (0.655) \n  \n\n Profession: Small Employer \n    −0.024 \n    −0.209 \n    −0.388 \n  \n\n  \n    (0.086) \n    (0.413) \n    (0.742) \n  \n\n Profession: Self Employed \n    0.007 \n    −0.050 \n    −0.082 \n  \n\n  \n    (0.074) \n    (0.352) \n    (0.626) \n  \n\n Profession: Employee \n    0.037 \n    0.066 \n    0.143 \n  \n\n  \n    (0.084) \n    (0.395) \n    (0.699) \n  \n\n Profession: Temporary Worker \n    0.002 \n    −0.066 \n    −0.100 \n  \n\n  \n    (0.075) \n    (0.357) \n    (0.634) \n  \n\n Profession: Junior \n    −0.110 \n    −0.603 \n    −1.022 \n  \n\n  \n    (0.084) \n    (0.403) \n    (0.723) \n  \n\n Num.Obs. \n    1593 \n    1593 \n    1593 \n  \n\n R2 \n    0.512 \n     \n     \n  \n\n R2 Adj. \n    0.495 \n     \n     \n  \n\n AIC \n    1265.2 \n    1317.3 \n    1315.6 \n  \n\n BIC \n    1560.8 \n    1607.5 \n    1605.8 \n  \n\n Log.Lik. \n    −577.622 \n    −604.647 \n    −603.825 \n  \n\n F \n    30.417 \n    11.497 \n    8.800 \n  \n\n RMSE \n    0.35 \n    0.34 \n    0.34 \n  \n\n\n\n\n\n\n\n\n\nCompare the coefficients from our probit model to that presented in the first column of Table 1A in the article.\nHow do our three models compare? There are some easy rules-of-thumb for roughly converting the values of coefficients between the linear, logit and probit models. Try the following:\n\n\nDivide the probit coefficients by 1.6 to get an approximation of the logit coefficients\nDivide the logit coefficients by 4 to get an approximation of linear coefficients\nMultiply probit coefficients by 0.4 to get an approximation of linear coefficients\n\nThese rules are not very precise in the case of this large model, but try them out on results from smaller models too."
  },
  {
    "objectID": "materials/worksheets/draft-worksheets_w04.html#exercise-2-predicting-the-frequency-of-social-interaction-using-poisson",
    "href": "materials/worksheets/draft-worksheets_w04.html#exercise-2-predicting-the-frequency-of-social-interaction-using-poisson",
    "title": "Week 4 Computer Lab Worksheet",
    "section": "Exercise 2: Predicting the Frequency of Social Interaction using Poisson",
    "text": "Exercise 2: Predicting the Frequency of Social Interaction using Poisson\nFor this exercise, we will use data from Weiss et al. (2021) to reproduce the results they present in the first column of their Supplementary Table S6. The article can be accessed online here; the table of interest is on page 78, and a brief description of the results is offered on page 32:\n\n… we explored the possibility that trait differences may be associated with the frequency of social interactions … reported during the ESM [experience-sampling method] period. To this end, we conducted … Poisson regression analyses, controlling for overall participant response rate. As Supplementary Table S6 shows, only few measures predicted such possible selection effects: the overall number of social interactions was reliably predicted only by zero-sum beliefs, such that individuals holding more negative views regarding the antagonistic nature of social interactions and relationships reported a lower number of overall interactions.\n\nRead the article to get a better understanding of the data. For our immediate purposes, it’s enough to know that we want to regress a measurement of the number of social interactions on a set of demographic and dispositional predictors.\nWe can load the dataset called EverydayTrust.Rds from the course website. Note that if we are reading in data files from an internet source with the readRDS() function, we need to call it using the url() function. For simplicity, we’ll abreviate the name of the data object as et.\n\net <- readRDS(url(\"https://cgmoreh.github.io/HSS8005-data/EverydayTrust.Rds\"))\n\nHave a look at the dataset. Note that variables with the suffix “_c” are grand-mean-centred versions of the base variables; the Gender variable has a dummy-coded version and a so-called simple effect-coded version (Gender_e, coded as -1 for Female and 1 for Male), with which the intercept estimates the grand mean rather than the value 0. The authors use this latter version when fitting the model. The variable names are similar to the labels that appear in Table S6, so they are easy to identify.\n\n\nFit the Poisson model using the variables shown in Table S6 using the formula skeleton below:\n\n\n... <- glm(... ~ ..., family=\"poisson\", data = ...)\n\n\nCheck the model summary and compare the results with those in Table S6\n\n\n\n\n\nCall:\nglm(formula = Number_of_Social_Interactions ~ Gender_e + Age_c + \n    Political_Orientation_c + Religiosity_c + Trust_Scale_c + \n    Distrust_c + Moral_Identity_c + Zero_Sum_Belief_c + Social_Value_Orienation_c + \n    Signal_Response_Rate, family = \"poisson\", data = et)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-4.2050  -0.7750  -0.0146   0.7306   3.0191  \n\nCoefficients:\n                           Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                1.017743   0.075622  13.458  < 2e-16 ***\nGender_e                  -0.024457   0.017591  -1.390 0.164427    \nAge_c                      0.002571   0.001550   1.659 0.097146 .  \nPolitical_Orientation_c   -0.004787   0.008308  -0.576 0.564502    \nReligiosity_c              0.014473   0.017348   0.834 0.404112    \nTrust_Scale_c              0.016144   0.021150   0.763 0.445264    \nDistrust_c                -0.037711   0.019505  -1.933 0.053187 .  \nMoral_Identity_c          -0.020356   0.017854  -1.140 0.254216    \nZero_Sum_Belief_c         -0.068133   0.018167  -3.750 0.000177 ***\nSocial_Value_Orienation_c  0.002162   0.001484   1.456 0.145263    \nSignal_Response_Rate       0.068348   0.003474  19.675  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1144.66  on 397  degrees of freedom\nResidual deviance:  602.97  on 387  degrees of freedom\n  (29 observations deleted due to missingness)\nAIC: 2272.9\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "Quantitative analysis \n        \n        \n            HSS8005 • Intermediate/Advanced stream • 2023\nNewcastle University (UK)\n        \n        \n            A second course in applied statistics and probability for the understanding of society and culture. It is aimed at an interdisciplinary audience through real-life research examples from various fields in the social sciences and humanities. The course emphasizes the scientific application of statistical methods, developing a reproducible research workflow, and computational techniques.\n        \n    \n\n\n\n\n\nModule leader\n\n   Dr. Chris Moreh\n   HDB.4.106\n   chris.moreh@newcastle.ac.uk\n   Tutorial booker\n \n\n\n\nTeaching Assistants\n\n   Bilal Alsharif\n   Fengting Du\n\n\n\n\n\nSession dates\n\n   Thursdays\n    Check on your Timetable app\n   Lecture: 10:00-11:30\n   Labs:   13:00-14:30 (Group 03)        14:30-16:00 (Group 04)  \n\n\n\nAssessment\n\n   26th April 2023\n   3,500-word long research report\n   Submit to Turnitin via Canvas\n\n\n\n\n Chris’s mastodon feed\nwhere he posts stuff of interest to #HSS8005\n\n\n\n\n\n\nModule overview\nThis module is offered by School X - Researcher Education and Development to postgraduate students within the Faculty of Humanities and Social Sciences at Newcastle University. The module aims to provide a broad applied introduction to more advanced methods in quantitative analysis for students from various disciplinary backgrounds. See the module plan page for details about the methods covered. The course content consists of eight lectures (1.5 hours each) and eight IT labs (1.5 hours) . The course stands on three pillars: application, reproducibility and computation.\nApplication: we will work with real data originating from large-scale representative surveys or published research, with the aim of applying methods to concrete research scenarios. IT lab exercises will involve reproducing small bits of published research, using the data and (critically) the modelling approaches used by the authors. The aim is to see how methods have been used in practice in various disciplines and learn how to reproduce (and potentially improve) those analyses. This will then enable students to apply this knowledge to their own research questions. The data used in IT labs may be cleansed to allow focusing more on modelling tasks than on data wrangling, but exercises will address some of the more common data manipulation challenges and will cover essential functions. Data cleansing scripts will also be provided so that interested students can use them in their own work.\nReproducibility: developing a reproducible workflow that allows your future self or a reviewer of your work to understand your process of analysis and reproduce your results is essential for reliable and collaborative scientific research. We enforce the ideas and procedures of reproducible research both through replicating published research (see above) and in our practice (in the IT labs and the assignment). For an overview of why it’s important to develop a reproducible workflow early on in your research career and how to do it using (some) of the tools used in this module, read Chapter 3 of TSD (see Resources>Readings). It’s also worth reading through Kieran Healy’s The Plain Person’s Guide to Plain Text Social Science, although there are now better software options than those discussed there. In this course, we will be using a suite of well-integrated free and open-source software to aid our reproducible workflow: the  statistical programming language and its currently most popular dialect – the {tidyverse} – via the  IDE for data analysis, and  for scientific writing and publishing (see Resources>Software).\nComputation: the development of computational methods underpins the application of the most important statistical ideas of the past 50 years (see Andrew Gelman’s article on these developments here or an online workshop talk here; Richard McElreath’s great talk on Science as Amateur Software Development is well worth watching too). This module aims to develop basic computational skills that allow the application of complex statistical models to practical scientific problems without advanced mathematical knowledge, and which lay the foundation on which students can then pursue further learning and research in computational humanities and social sciences.\n\nThe course and the website were written and are maintained by Chris Moreh.\n\n\nPrerequisites\nTo benefit the most from this module, students are expected to have a foundational level of knowledge in quantitative methods: a good understanding of data types and distributions, familiarity with inferential statistics, and some exposure to linear regression. This is roughly equivalent to the content covered in the Introductory stream of the module or a textbook such as OpenIntro Statistics (which you can download for free in PDF).\nThose who don’t feel completely up to date with linear regression but are determined to advance more quickly and read/practice beyond the compulsory material during weeks 1-3 are also encouraged to sign up.\nThose with a stronger background in multiple linear regression (e.g. students with undergraduate-level training in econometrics) will still benefit from weeks 1-3 as the approach we are taking is probably different from the one they are familiar with.\nNo previous knowledge of  or command-based statistical analysis software is needed. Gaining experience with using statistical software is part of the skills development aims of the module. However, it is not a general data science module, and the IT labs will cover a very limited number of functions (from both base R, the tidyverse and other reliable user-written packages) that are most useful for tackling specific analysis tasks. Students are advised to complete some additional self-paced free online training in the use of the software, such as Data Carpentry’s R for Social Scientists, and to consult Wickham, Çetinkaya-Rundel and Grolemund’s R for Data Science (2nd ed.) online book."
  },
  {
    "objectID": "materials/info/info_w07.html",
    "href": "materials/info/info_w07.html",
    "title": "Week 7  The unobserved",
    "section": "",
    "text": "Readings\nTextbook\n\nChapters 13 and 14 in Mehmetoglu, M. & Mittner, M. (2022) Applied statistics using R: a guide for the social sciences. London: Sage (NCL library access here)\n\nVideo\n\nKubinec, R. (2019) An introduction to latent variable models for data science. Sage Research Methods (video file, 00:17:44) (NCL library access here)\n\nApplication\n\nEjrnæs, A., & Jensen, M. D. (2022) Go Your Own Way: The Pathways to Exiting the European Union. Government and Opposition, 57(2), 253-275. https://doi.org/10.1017/gov.2020.37 (The accepted manuscript version can be downloaded from here)\n\n\n\n\n\n\nReferences\n\nDavid, F. N. 1955. “Studies in the History of Probability and Statistics i. Dicing and Gaming (a Note on the History of Probability).” Biometrika 42 (1/2): 1–15. https://doi.org/10.2307/2333419.\n\n\nEl-Shagi, Makram, and Alexander Jung. 2015. “Have Minutes Helped Markets to Predict the MPC’s Monetary Policy Decisions?” European Journal of Political Economy 39 (September): 222–34. https://doi.org/10.1016/j.ejpoleco.2015.05.004.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and other stories. Cambridge: Cambridge University Press. https://doi.org/10.1017/9781139161879.\n\n\nLord, R. D. 1958. “Studies in the History of Probability and Statistics.: VIII. De Morgan and the Statistical Study of Literary Style.” Biometrika 45 (1/2): 282–82. https://doi.org/10.2307/2333072.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. Second. CRC Texts in Statistical Science. Boca Raton: Taylor and Francis, CRC Press.\n\n\nMulvin, Dylan. 2021. Proxies: The Cultural Work of Standing in. Infrastructures Series. Cambridge, Massachusetts: The MIT Press.\n\n\nSenn, Stephen. 2003. “A Conversation with John Nelder.” Statistical Science 18 (1): 118–31. https://doi.org/10.1214/ss/1056397489."
  },
  {
    "objectID": "materials/worksheets/worksheets_w07.html#setup",
    "href": "materials/worksheets/worksheets_w07.html#setup",
    "title": "Week 7 Computer Lab Worksheet",
    "section": "Setup",
    "text": "Setup\nIn Week 1 you set up R and RStudio, and an RProject folder (we called it “HSS8005_labs”) with an .R script and a .qmd or .Rmd document in it (we called these “Lab_1”). Ideally, you saved this on a cloud drive so you can access it from any computer (e.g. OneDrive). You will be working in this folder. If it’s missing, complete Task 2 from the Week 1 Lab.\nYou can create and work in either an .R script or a .qmd/.Rmd for this week’s exercises (e.g. “Lab_7”), but the .qmd/.Rmd is recommended as it allows you to record longer notes and to render/knit your work to an easily readable output format.\nAlso install and load the packages that we will use in this session. Apart from packages that we have already used before, there are a number of new packages that we will explore:\n\n# Load required packages\n# Assumes that the pacman package is already installed; if it's not, install it first\npacman::p_load(tidyverse, \n               sjlabelled, \n               sjmisc,\n               modelsummary,\n               marginaleffects,\n               lme4,\n               psych,\n               lavaan,\n               lavaanPlot,\n               semPlot)"
  },
  {
    "objectID": "materials/worksheets/worksheets_w07.html#exercise-1-exploratory-factor-analysis",
    "href": "materials/worksheets/worksheets_w07.html#exercise-1-exploratory-factor-analysis",
    "title": "Week 7 Computer Lab Worksheet",
    "section": "Exercise 1: (Exploratory) Factor Analysis",
    "text": "Exercise 1: (Exploratory) Factor Analysis\nIn the first exercises we will use a dataset containing data collected from members of a fitness centre in Norway in 2014 (Mehmetoglu and Mittner 2021) (The description of the methods and analysis also relies mostly on Chapters 13 and 14 in Mehmetoglu and Mittner (2021)). The club members were asked to indicate how well having an attractive face and being sexy described them as a person using an ordinal scale (1 = very badly to 6 = very well). Using a similar scale (1 = not at all important to 6 = very important), the members were also asked to indicate how important various motivation for working out were:\n\n\n\n\n\n Name \n    Label \n  \n\n\n lweight \n    How important is following to workout- to loose weight \n  \n\n calories \n    How important is following to workout- to burn calories \n  \n\n cweight \n    How important is following to workout- to control my weight \n  \n\n stress \n    How important is following to workout - to help manage stress \n  \n\n tension \n    How important is following to workout - to release tension \n  \n\n relax \n    How important is following to workout - to mentally relax \n  \n\n body \n    How important is following to workout- to have a good body \n  \n\n appear \n    How important is following to workout- to improve my appearance \n  \n\n attract \n    How important is following to workout- to look more attractive \n  \n\n muscle \n    How important is following to workout- to develop my muscles \n  \n\n strength \n    How important is following to workout- to get stronger \n  \n\n endur \n    How important is following to workout- to increase my endurance \n  \n\n face \n    How well does the following describe you as a person -  attractive face \n  \n\n sexy \n    How well does the following describe you as a person - sexy \n  \n\n\n\n\nThe workout dataset can be loaded from the course website:\n\n# Load data\nworkout <- readRDS(url(\"https://cgmoreh.github.io/HSS8005/data/workout.Rds\"))\n\n\nTo inspect and better understand the dataset, apply some of the summary functions we practised in previous weeks to this data (e.g. using modelsummary, gtsummary, summarytools or something else).\n\n...\n\n\n\n\n\nFor the first exercise, we’ll select a few variables from the dataset and keep only complete cases with non-missing values:\n\nefa_data <- workout |> \n  select(stress:attract) |> \n  drop_na()\n\nThe six selected variables are the following:\n\n\n\n\n\n Name \n    Label \n  \n\n\n stress \n    How important is following to workout - to help manage stress \n  \n\n tension \n    How important is following to workout - to release tension \n  \n\n relax \n    How important is following to workout - to mentally relax \n  \n\n body \n    How important is following to workout- to have a good body \n  \n\n appear \n    How important is following to workout- to improve my appearance \n  \n\n attract \n    How important is following to workout- to look more attractive \n  \n\n\n\n\nWe can notice that the selected variables can roughly be seen to refer to two conceptual dimensions (latent factors): mental well-being and physical appearance.\nA common motivation for an (exploratory) factor analysis is to reduce a large number of variables down to a meaningful and manageable number of “factors” - or latent variables - that can explain the covariance/correlation among that larger set of observed - measured - variables. Each factor corresponds to a subset of observed variables that are relatively highly correlated. The first steps in a factor analysis are, thus, deciding the number of factors to extract and factor extraction. Factor extraction revolves around inspecting the diagonals of a correlation matrix that includes all the correlations among the observed variables of interest. In a raw correlation matrix, the values on the diagonals are all 1s, because each variable is perfectly correlated with itself. For example, a raw correlation matrix for our sample data would look like this:\n\n# rounded to two decimals for readability\ncor(efa_data) |> \n  round(2)\n\n        stress tension relax body appear attract\nstress    1.00    0.83  0.75 0.02  -0.02   -0.05\ntension   0.83    1.00  0.82 0.00  -0.02   -0.08\nrelax     0.75    0.82  1.00 0.12   0.04    0.00\nbody      0.02    0.00  0.12 1.00   0.76    0.71\nappear   -0.02   -0.02  0.04 0.76   1.00    0.86\nattract  -0.05   -0.08  0.00 0.71   0.86    1.00\n\n\nIn the factor analysis process our aim is to modify these diagonal values to best suit our aims - the various factor extraction methods target these diagonal values (apart from the Maximum Likelihood method, which manipulates the off-diagonal values). Two of the most commonly employed extraction methods are the Principal Axis factor (PA) and the Principal Components Analysis (PCA) methods. The PA method inserts estimates of the common/shared variance (also called communality) in the diagonals of the starting correlation matrix instead of 1s. Communality values are obtained by estimating the squared multiple correlation (smc) of each variable with all the other variables in the matrix (i.e. the multiple R-squared values obtained from regressing each variable on the remaining variables). Manually, we could calculate these communalities like this:\n\ncor_table <- cor(efa_data)                               # Save the raw correlation matrix as an object\n\ndiag(cor_table) <- (1 - 1 / diag(solve(cor_table)))      # Calculate and replace the diagonal of  the matrix with the estimated communalities\n## or, alternatively, using the `smc()` function from the {psych} package:\ndiag(cor_table) <- smc(efa_data) \n\ncor_table |> round(2)                                    # Print the correlation matrix with two decimals precision\n\n        stress tension relax body appear attract\nstress    0.70    0.83  0.75 0.02  -0.02   -0.05\ntension   0.83    0.79  0.82 0.00  -0.02   -0.08\nrelax     0.75    0.82  0.71 0.12   0.04    0.00\nbody      0.02    0.00  0.12 0.61   0.76    0.71\nappear   -0.02   -0.02  0.04 0.76   0.79    0.86\nattract  -0.05   -0.08  0.00 0.71   0.86    0.75\n\n\n\n\n\n\n\n\nCompare\n\n\n\nCompare the values on the diagonal to those obtained from regressing each variables in the dataset on all the remaining variables; eg:\n\nlm_stress <- lm(stress ~ tension + relax + body + appear + attract, data = efa_data)\nlm_tension <- lm(tension ~ stress + relax + body + appear + attract, data = efa_data)\n\n... etc.\n\nsummary(lm_stress)$r.squared\nsummary(lm_tension)$r.squared\n\n... etc.\n\n\n\nThe reason why PA uses communalities in the diagonals is that it assumes that some of the variance in the variables is caused by some other unique sources which ideally should be removed from the analysis. Conversely, PCA uses 1s in the starting diagonals in the correlation matrix without sorting out the variance caused by other sources than the factors themselves. In this respect, PCA could be said to analyse variance (1s in the diagonals) whereas PA (and the other extraction methods) analyses covariance (communalities in the diagonals).\nThe next step in factor extraction is to compute eigenvalues and eigenvectors from this correlation matrix which are then used to compute factor loadings. Eigenvectors are sets of weights (\\(w\\)) that generate factors with the largest possible eigenvalues, while eigenvalues (\\(e\\)) are variances captured by these factors. Factor loadings reflect correlations between observed variables and their respective factors, unless factors are correlated. Factors can be assumed correlated when rotating the factor solution using a type of oblique rotation such as “promax” or “oblimin”; otherwise, PA and PCA assume and produce an orthogonal (no correlation between factors) solution initially. As a result, if we square these correlations, the results will show us how much variance of each observed variable is explained by each factor.\nThe eigenvalues are a common way of deciding on the number of factors to extract. In PCA, factors associated with eigenvalues greater than 1 are generally recommended to be retained for interpretation. The idea here is that the factor retained should explain at least as much variance as one observed variable contributes, a situation represented by 1s in the diagonal. In the case of PA, since we use communalities (which are less than 1) instead of 1s in the diagonal, a common strategy is to choose eigenvalues greater than the average of the initial communalities.\nOther strategies for choosing the number of factors to extract are scree tests, parallel analysis and theoretical motivations. The scree test is about examining a plot/curve, produced after factor extraction, containing the eigenvalues on the Y-axis and the factors on the X-axis. The idea of the scree test is that factors along the tail of the curve represent mostly random error variance (trivial eigenvalues), and consequently, the factor solution just before the levelling of the curve should be chosen. Parallel analysis is about estimating the same factor model as the original one using randomly simulated data, resembling the original data in terms of both the number of variables and observations. Eigenvalues obtained from the simulated data are subsequently averaged and contrasted with their counterparts from the original data. A common recommendation is that if the eigenvalue of a factor from the original data proves to be larger than the average (or, alternatively, the 95th percentile) of the eigenvalues from the simulated data, the factor should be retained. Otherwise, the factor would be considered no more substantial than a random factor and thus discarded.\nIn R the psychpackage provides a variety of functions for performing factor analysis. The fa.parallel() function runs a parallel analysis including a scree plot. In the command below we specify that the parallel analysis should be done using the PA extraction method (fm=\"pa\") and the same method should be used for the eigenvalues (fa=\"fa\"). With the argument SMC=\"TRUE\" we can also request that squared multiple correlations be used in the diagonal of the correlation matrix at the start of the estimation:\n\nparallel_analysis <- fa.parallel(efa_data,\n      fm=\"pa\", fa=\"fa\", SMC=\"TRUE\")\n\n\n\n\nParallel analysis suggests that the number of factors =  2  and the number of components =  NA \n\n\nAlternatively, to run a Principal Component Analysis instead, we can write:\n\nfa.parallel(efa_data, fa=\"pc\")\n\n\n\n\nParallel analysis suggests that the number of factors =  NA  and the number of components =  2 \n\n\nThe scree plot suggests the existence of two obvious factors before the curve levels off. In the code above we have saved the results to an object so that we can also print out more detailed numerical results using the print() function:\n\nprint(parallel_analysis)\n\nCall: fa.parallel(x = efa_data, fm = \"pa\", fa = \"fa\", SMC = \"TRUE\")\nParallel analysis suggests that the number of factors =  2  and the number of components =  NA \n\n Eigen Values of \n\n eigen values of factors\n[1]  2.34  2.28  0.00 -0.07 -0.08 -0.12\n\n eigen values of simulated factors\n[1]  0.28  0.15  0.05 -0.03 -0.11 -0.19\n\n eigen values of components \n[1] 2.61 2.56 0.32 0.23 0.16 0.12\n\n eigen values of simulated components\n[1] NA\n\n\nWe could also compare the average smc() scores to the eigenvalues:\n\nsmc(efa_data) |> mean()\n\n[1] 0.7246744\n\n\nAgain, only two of the eigenvalues are greater that the mean of the squared multiple correlations between the variables. Finally, a theoretical reasoning also supports the choice for two factors being drawn out from this set of six variables, given that, as noted earlier, they appear to roughly map onto motivations relating to either mental well-being or physical appearance.\nThe actual extraction of the factors/principal components, once the most appropriate number of factors has been decided, can be done using the fa() and principal() functions from psych. These functions also provide various extraction methods and rotation options. It is generally useful to rotate the initial factor solution in order to obtain a more easily interpretable factor solution. An easily interpretable factor solution is associated with an output that contains a factor loading (pattern) matrix with variables with the maximum possible loading (close to 1) on one factor and the minimum possible loading (close to 0) on the remaining factor(s); this is often referred to as a ‘simple structure’. Orthogonal rotation options impose that a 90-degree angle is kept between factor axes while rotating them. An alternative approach, oblique rotation, relaxes this restriction, and is often preferred given that arguably factors (latent variables) measuring behavioural phenomena common in social science research are somewhat correlated, and oblique rotation can take this correlation into account by first estimating the correlation between the factors and then generating a solution.\nThe most widely used orthogonal rotation technique is “varimax” rotation, which maximizes the variance of the squared loadings for each factor, thus polarizing loadings so that they are either high or low, making it easier to identify factors with specific variables. Rotation does not influence the total variance explained by the factors. However, the total variance explained gets distributed differently among the factors (i.e., eigenvalues change). Suppose that two factors explain 75 per cent variance together, with 48 per cent and 27 per cent of the variance attributable to the first and second factor, respectively. After rotation, the factors would together still explain 75 per cent variance, but now with, say, 44 per cent and 31 per cent of the total variance attributed to the first and second factor, respectively. Relatedly, the total amount of variance of each variable explained by the factors (i.e., communality) would also stay the same but the factor loadings would change after rotation.\nThe most common oblique rotation technique is “promax”, which starts with an orthogonal rotation (varimax) in which the loadings are, first, raised to a specific power (2, 3 or 4) and then the solution is rotated to allow for correlations among the factors.\nLet’s use the fa() function to extract two factors using the PA method and applying a “varimax” rotation. Since our two factors represent two different phenomena (mental well-being or physical appearance) we do not assume a strong correlation between the two factors, and therefore an orthogonal rotation is substantiated. The fa() function also uses an iterative version of PA by default, which we can turn off by specifying max.iter = 0 if we want to. Iterative PA is basically a PA run several times. While PA starts and completes the factor extraction process with one set of estimated communalities (squared multiple correlations), IPA replaces these estimated communalities by new estimates emerging from the factor extraction process each time until the difference between the two communalities (last inserted and last estimated) is minimized. The fa() function uses the default argument min.err = 0.001, meaning that the estimation iterates until the change in communality is less than 0.001.\n\nfactor_model <- fa(efa_data,\n              nfactors = 2, \n              fm=\"pa\",\n              rotate = \"varimax\")\n\nWe can inspect the complete results from the factor analysis by printing the model object:\n\nfactor_model\n\nWe can also extract more specific information rather than inspecting the entire output. For example, we can check the factor loadings and eigenvalues:\n\nprint(factor_model$loadings, digits=4, cutoff=0)\n\n\nLoadings:\n        PA1     PA2    \nstress   0.8662 -0.0287\ntension  0.9522 -0.0480\nrelax    0.8689  0.0465\nbody     0.0575  0.7990\nappear   0.0093  0.9550\nattract -0.0382  0.8943\n\n                  PA1    PA2\nSS loadings    2.4168 2.3554\nProportion Var 0.4028 0.3926\nCumulative Var 0.4028 0.7954\n\n\nWe can see in this output how the first three variables (stress, tension and relax) load strongly on the first factor, and the last three variables (body, appear and attract) load strongly on the second factor. The factor loadings table can be read both vertically and horizontally. When we interpret the matrix vertically, we locate the correlations between a factor and all the observed variables. For example, the loading of stress on factor 1 is 0.8662. Squaring this value - 0.8662^2 = 0.7503 - tells us that roughly 75% per cent of the variance of stress is explained by factor 1. When we interpret the table horizontally, we obtain item communalities. For instance, we see that the loadings of tension on factor 1 and factor 2 are 0.9522 and -0.0480, respectively. Squaring and adding these two values together - 0.9522^2 + (-0.0480)^2 = 0.9089 - would show us the proportion (about 90%) of the total variance of tension that is explained by factor 1 and factor 2 in tandem. The remaining 10% represents the unique or unexplained variance.\nWe can also visualise these results with the fa.diagram() and fa.plot() functions:\n\nfa.diagram(factor_model, digits = 2)\n\n\n\n\n\nfa.plot(factor_model)\n\n\n\n\nIn most cases the aim of an exploratory factor analysis is to use factors in subsequent analysis. For this, we first need a metric for the two hypothetical constructs. We can either use the estimated factor scores directly or we can generate factors by, for example, taking either the sum or average of the variables expressing each factor. We will choose to take the average to keep the factor metric on the same scale (1−6) as the original observed variables, using the scoreItems() function from psych. Then, we can test the reliability of this summed scale based on Cronbach’s \\(\\alpha\\) coefficient.\n\n# First, we compile a list of the variables:\nitemlist <- list(mental=c(\"stress\",\"tension\",\"relax\"),\n                 physical=c(\"body\",\"appear\",\"attract\"))\nsummateds <- scoreItems(itemlist, efa_data, \n                         min=1, max=6, totals = FALSE)\nfactordata <- as_data_frame(summateds$scores)\n\n# Merge the factordata variables with the dataset:\n\nefa_data <- bind_cols(efa_data, factordata)\n\n# Check the variables in the dataset:\nnames(efa_data)\n\n[1] \"stress\"   \"tension\"  \"relax\"    \"body\"     \"appear\"   \"attract\"  \"mental\"  \n[8] \"physical\"\n\n\nTo test the reliability of the factors created, we can use the alpha() function from `{psych}’:\n\n# We run the alpha check on the two items separately:\n\nmental <- efa_data |> select(stress:relax)\nphysical <- efa_data |> select(body:attract)\n\n# We can save the output to objects and inspect them\nalpha_mental <- alpha(mental)\nalpha_physical <- alpha(physical)\n\n# Or we can print out only the overall alpha values directly\nalpha(mental)$total$std.alpha\n\n[1] 0.9234774\n\nalpha(physical)$total$std.alpha\n\n[1] 0.9124331\n\n\nIn common practice an \\(\\alpha\\) level higher than 0.7 is taken as satisfactory, showing a good fit of the items. Both our factors have a high \\(\\alpha\\) value, so we have additional evidence that the variables chosen fit together well on each factor.\n\nEFA practice Try to redo the analysis above, but this time including all the variables relating to “How important is following to workout …” variables from the original workout dataset."
  },
  {
    "objectID": "materials/worksheets/worksheets_w07.html#exercise-2-latent-path-analysis",
    "href": "materials/worksheets/worksheets_w07.html#exercise-2-latent-path-analysis",
    "title": "Week 7 Computer Lab Worksheet",
    "section": "Exercise 2: Latent Path Analysis",
    "text": "Exercise 2: Latent Path Analysis\nConfirmatory Factor Analysis (CFA) and Latent Path Analysis (LPA) are two of the most commonly used Structural Equation Modelling techniques in the social sciences. Confirmatory factor analysis is used to assess a hypothesized latent factor structure containing a set of indicators and one or more latent variables. Latent path analysis is used not only to examine a factor structure but also to test hypothesized structural relationships among the latent variables. The factor structure is concerned with the relationships between indicators and latent variables, whereas the structural relationships concern links between latent variables. The former is referred to as the measurement part, while the latter is named the structural part; together they comprise LPA.\nIn this exercise we will use the same workout data we started off from in Exercise 1. The analysis presented by Mehmetoglu and Mittner (2021) begins by proposing a number of hypotheses concerning motivations for working out in a fitness club based on evolutionary psychology theories:\n\nH1: The more attractive one perceives herself/himself, the more the person wants to work out to improve her/his physical appearance (i.e., Attractive → Appearance).\nH2: The more the person wants to work out to improve her/his physical appearance, the more s/he wants to work out to build up muscles (i.e., Appearance → Muscle).\nH3: The more the person wants to work out to improve her/his physical appearance, the more s/he wants to work out to lose weight (i.e., Appearance → Weight).\nH4: The more attractive one perceives herself/himself will indirectly influence the person to work out more to build up muscles (i.e., Attractive → Appearance → Muscle).\nH5: The more attractive one perceives herself/himself will indirectly influence the person to work out more to lose weight (i.e., Attractive → Appearance → Weight).\n\nIn an SEM framework it is common to visualise this set of hypotheses in a path diagram. Using the lavaan package, we can write the measurement and structural model equations, fit the structural equation model and plot the model like this:\n\n# First, remove all objects from the Environment, except for the \"workout\" data\nrm(list=setdiff(ls(), \"workout\"))\n\n\n# Specify the model structure:\nfull.lpa.mod <- '\n              # Measurement model (latent variables)\n                Attractive =~ face + sexy\n                Appearance =~ body + appear + attract\n                Muscle =~ muscle + strength + endur\n                Weight =~ lweight + calories + cweight\n              # Structural model (regressions)\n                Appearance ~ Attractive\n                Muscle ~ Appearance\n                Weight ~ Appearance\n              '\n\n# Estimate the model\nest.full.lpa.mod <- sem(full.lpa.mod, data=workout)\n\n# Plot the model\n## with lavaanPlot()\nlavaanPlot(model = est.full.lpa.mod)\n\n\n\n\n## or semPaths()\nsemPlot::semPaths(est.full.lpa.mod, title = FALSE,  layout = \"tree2\", nCharNodes = 0)\n\n\n\n\nEstimating a LPA model proceeds in two steps: we first establish a psychometrically sound (i.e., valid and reliable) measurement model and subsequently test the structural model. The measurement part of the LPA model includes the relationship between each of our four latent variables (Attractive, Appearance, Muscle and Weight) and its respective indicators. The measurement model is a standard CFA, and can be fit separately like this:\n\nmeas.lpa.mod <- '\n                Attractive =~ face + sexy\n                Appearance =~ body + appear + attract\n                Muscle =~ muscle + strength + endur\n                Weight =~ lweight + calories + cweight\n                '\nest.meas.lpa.mod <- cfa(meas.lpa.mod, data = workout)\n\nWe can inspect the results using the summary() function, with some additional options included:\n\nsummary(est.meas.lpa.mod, fit.measures = TRUE, standardized = TRUE)\n\nSome of the model fit indices (RMSEA > 0.1, TLI < 0.9, etc.) could be improved. The root mean squared error of approximation (RMSEA) takes the model complexity and sample size into consideration and penalizes models with too many parameters to estimate (i.e., with low degrees of freedom, df) and accordingly favours simpler models (i.e., with higher df). As we decrease the df (i.e., include more parameters to estimate in our model), the RMSEA value increases. High RMSEA values will be a sign of poor model fit, and RMSEA values greater than 0.10 generally indicate poor model fit. The Tucker–Lewis index (TLI) also generally ranges from 0 to 1, and higher values are desirable. TLI values greater than 0.90 are generally associated with acceptable model fit.\nMehmetoglu and Mittner (2021) suggest that correlating the error variances of two different pairs of indicators (“muscle” and “endur”, “lweigh” and “body”) would improve the model fit. This modification involves:\n\nmeas.lpa.mod2 <- '\n                Attractive =~ face + sexy\n                Appearance =~ body + appear + attract\n                Muscle =~ muscle + strength + endur\n                Weight =~ lweight + calories + cweight\n                muscle ~~ endur \n                lweight ~~ body\n                '\nest.meas.lpa.mod2 <- cfa(meas.lpa.mod2, data = workout)\n\nThe revised model is an improvement, although the RMSA is still slihghtly above 0.10.\nThe structural part extends the measurement with the hypothesized relationship among the latent variables.\n\nfull.lpa.mod <- '\n              # Measurement model (latent variables)\n                Attractive =~ face + sexy\n                Appearance =~ body + appear + attract\n                Muscle =~ muscle + strength + endur\n                Weight =~ lweight + calories + cweight\n                muscle ~~ endur \n                lweight ~~ body\n              # Structural model (regressions)\n                Appearance ~ Attractive\n                Muscle ~ Appearance\n                Weight ~ Appearance\n                '\nest.full.lpa.mod <- sem(full.lpa.mod, data = workout)\n\nWe can inspect the full model:\n\nsummary(est.full.lpa.mod, fit.measures = TRUE, standardized = TRUE)\n\nSince the theory underlying the model also statest that the covariance between the Muscle and the Weight factors should be set to 0, we can incorporate this into the model:\n\nfull.lpa.mod2 <- '\n              # Measurement model (latent variables)\n                Attractive =~ face + sexy\n                Appearance =~ body + appear + attract\n                Muscle =~ muscle + strength + endur\n                Weight =~ lweight + calories + cweight\n                muscle ~~ endur \n                lweight ~~ body\n                # Set covariance to 0:\n                Muscle ~~ 0*Weight\n              # Structural model (regressions)\n                Appearance ~ Attractive\n                Muscle ~ Appearance\n                Weight ~ Appearance\n                '\nest.full.lpa.mod2 <- sem(full.lpa.mod2, data = workout)\n\n\nsummary(est.full.lpa.mod2, fit.measures = TRUE, standardized = TRUE)\n\nThe assessment of the structural part is similar to that from a linear regression analysis. First, the sign, significance and size of path coefficients should be considered. Path coefficients are estimates that help us to assess the hypothesized relationships in the structural part. These path coefficients are typically presented in a standardized form, which is equivalent to standardized betas in linear regression. Standardized coefficients range generally between −1 and 1. The closer a path coefficient is to ±1 the stronger the relationship (positive/negative) is. The closer a path coefficient is to 0, the weaker the relationship is. Standardized beta coefficients equal to or less than 0.09 indicate a small effect, coefficients between 0.09 and 0.2 indicate a moderate effect, and coefficients larger than 0.2 indicate large effect. In our model, all the signs of the coefficients are in the hypothesized direction. That is, Attractive has a large and positive effect on Appearance, and Appearance has a large and positive effect on both Muscle and Weight. Finally, all of the standardized coefficients are statistically significant at 0.01. All these findings provide clear support for the first three of our study hypotheses (H1, H2, and H3). To address H4 and H5, we need to estimate the indirect effect of Attractive (via Appearance) on Muscle and Weight. In lavaan, this involves setting labels for the path coefficients (e.g. a, b1, b2), then using these labels to create new parameters (e.g. ind1 and ind2) using the := operator:\n\nfull.lpa.mod3 <- '\n              #Measurement model (latent variables)\n                Attractive =~ face + sexy\n                Appearance =~ body + appear + attract\n                Muscle =~ muscle + strength + endur\n                Weight =~ lweight + calories + cweight\n                muscle ~~ endur \n                lweight ~~ body\n                Muscle ~~ 0*Weight #set covariance to 0\n              #Structural model (regressions)\n                Appearance ~ a*Attractive\n                Muscle ~ b1*Appearance\n                Weight ~ b2*Appearance\n              #Indirect effects\n                # of Attraction on Muscle\n                ind1 := a*b1 \n                # of Attraction on Weight\n                ind2 := a*b2 \n                '\nest.full.lpa.mod3 <- sem(full.lpa.mod3, data = workout)\n\n\nsummary(est.full.lpa.mod3, standardized=TRUE)\n\nFrom this final model, we find that Attractive has a moderate and positive indirect effect on both Muscle and Weight, and that these indirect effects are statistically significant at the 0.01 level."
  },
  {
    "objectID": "materials/worksheets/worksheets_w07.html#exercise-3-multilevel-path-model-coefficients-via-multilevel-modelling",
    "href": "materials/worksheets/worksheets_w07.html#exercise-3-multilevel-path-model-coefficients-via-multilevel-modelling",
    "title": "Week 7 Computer Lab Worksheet",
    "section": "Exercise 3: Multilevel path model coefficients via multilevel modelling",
    "text": "Exercise 3: Multilevel path model coefficients via multilevel modelling\nIn tis exercise we look at the analysis presented in Ejrnæs and Jensen (2021), who use cross-national data from 17 countries collected through the European Social Survey (Round 8, 2016) to identify scenarios, “pathways”, under which EU citizens would vote in a potential referendum for their country to leave the European Union. They begin by positing three theoretical models of “the micro-foundations of ‘hard Euroscepticism’/‘exit scepticism’”: utilitarian, identity and anti-elitist models. Their main method is a path analysis testing these theories, but they also employ multi-level logistic regression, principal component analysis (PCA) and cluster analysis at various points in their analysis. The main analysis is done in Stata (the PCA is done in SPSS).\nIn this exercise, we will look more closely at the following reported results:\n\nFigure 4: Multilevel path model \nAppendix 1: Multilevel logistic regression (marginal effects)\n\nWe will check how the results reported can be reproduced using multilevel modelling using the lme4() package, as practiced in Week 6. In R, lavaan has some limitations when it comes to fitting generalised multilevel SEM models.\nFirst, import the dataset:\n\n# Import the dataset\n# Also, drop unused value labels and select to keep only the variables that will be used\nejr <- sjlabelled::read_stata(\"https://cgmoreh.github.io/HSS8005/data/Ejrnaes21.dta\", drop.labels = TRUE) |> \n  select(c(vteurmmb, \n           trstprl, trstlgl, trstplc, trstplt, trstprt, \n           imueclt, imwbcnt, imbgeco, \n           eduyrs, hinctnta, country_num, \n           mnactic, agea, atchctr, gndr))\n\nprtvtfch, prtvtfee, prtvtbgb, prtvtcil, prtvtbis, prtvtbno, prtvtdru, prtclfch, prtclfee, prtclbgb, prtcldil, prtclbis, prtclbno, prtcldru, rlgdnach, rlgdngb, rlgdnis, rlgdnno, rlgdeach, rlgdegb, rlgdeis, rlgdeno, vteumbgb, vteubcmb, rshpsgb, marstgb, edlvdch, edlvdee, edubgb1, eduagb2, edagegb, edubil1, eduail2, edlvdis, edlvdno, edlvdru, edlvpdch, edlvpdee, edupbgb1, edupagb2, edagepgb, edupbil1, edupail2, edlvpdis, edlvpdno, edlvpdru, edlvfdch, edlvfdee, edufbgb1, edufagb2, edagefgb, edufbil1, edufail2, edlvfdis, edlvfdno, edlvfdru, edlvmdch, edlvmdee, edumbgb1, edumagb2, edagemgb, edumbil1, edumail2, edlvmdis, edlvmdno, edlvmdru\n\n\n\n\n\nData management\nOutcome variable\nThe outcome variable of interest originates from the survey question: “Imagine there were a referendum in [country] tomorrow about membership of the European Union. Would you vote for [country] to remain a member of the European Union or to leave the European Union?”. Responses are coded in the variable vteurmmb, which has five levels (tip: use the sjmisc::frq() function for a labelled frequency table of the variable), including also “Would submit a blank ballot paper”, “Would spoil the ballot paper” and “Would not vote” in addition to “Remain” and “Leave”. We will follow the authors in dichotomising the variable as “1” = Leave vs. “0” = all other non-missing values:\n\n# Recoding \"leave\" variable as dummy variable (with `dplyr`):\nejr <- ejr |> \n  mutate(leave = case_match(vteurmmb, \n                            \"2\" ~ 1,\n                            c(\"1\", \"33\", \"44\", \"55\") ~ 0)) \n\n### Notes: \n### - \"case_match\" has superseded the previous \"recode()\" function in dplyr 1.1.0. If the code above fails, make sure you have dplyr 1.1.0 installed; if not, install it first\n### - \"vteurmmb\" is a factor with 5 labelled levels; to be able to refer to the values when recoding, we need either to treat it as_numeric() or quote the levels using \"\". The resulting variable will be numeric in either case.\n\n## `sjmisc::rec()` is another useful option, especially with labelled data:\n\n# ejr <- ejr |>\n#   mutate(leave = rec(vteurmmb,\n#                      rec = \"2 = 1 [Leave];\n#                      1, 33, 44, 55 = 0\"))\n\nEndogenous variables\nIn the context of structural equation modelling, variables that are influenced by other variables in a model are called endogenous variables. Conversely, those not influenced by other variables are called exogenous. Additionally, we can differentiate manifest variables - those that we have directly observed and measured - from latent variables - those that we have not directly measured, but instead we estimate from other measured variables. Such latent variables can be, for example, the “factors” or “components” obtained from a factor analysis or PCA. A path analysis is a special version of a structural equation model in which all the variables are manifest (observed).\nThe two constructs used as endogenous variables in the Figure 4 model (“trust in the political establishment” and “support for multiculturalism”) are treated by the authors as manifest because they are entered into the model as indices created before the model-building, however, the indices are created as a result of a principal component analysis\n\n# Creating two trust-related composite variables\n\n\n## Select out the variables as data-frames         \ntrust_vars <- ejr |> \n  select(c(trstprl, trstlgl, trstplc, trstplt, trstprt)) |> \n  mutate(across(everything(), as_numeric))\n         \nmulticulti_vars <- ejr |> \n  select(c(imueclt, imwbcnt, imbgeco)) |> \n  mutate(across(everything(), as_numeric))\n\n\n## Create Cronbach's alpha coefficient scores using `alpha()` from the {psych} package \n## and add them to the \"data\" dataframe\n\nejr <- ejr |> \n  mutate(trust = alpha(trust_vars, check.keys = TRUE)$scores,\n         multi_culti = alpha(multiculti_vars, check.keys = TRUE)$scores)\n\nejr <- ejr |> \n  mutate(across(c(eduyrs, hinctnta, trust, multi_culti), as_numeric),\n         across(leave, as_factor))\n\nVariable standardisation\nTha authors also standardize the variables before modelling them. In R this can be done in various ways, including using the sjmisc::std() function:\n\n# Standardize variables using \"sjmisc::std()\"\nejr <- ejr |> \n  mutate(Zeducation1 = std(eduyrs),\n         Zincome1 = std(hinctnta),\n         Zmulti1 = std(multi_culti),\n         Ztrust1 = std(trust)\n         ) |> \n  mutate(across(c(Zeducation1, Zincome1, Zmulti1, Ztrust1, country_num), as_numeric))\n\nMultilevel model fitting\nWe now have all the variables in a format that can be modelled:\n\nF4_direct <- lme4::glmer(leave ~ Zeducation1 + Zincome1 + Ztrust1 + Zmulti1 + (1|country_num), family = binomial(link = \"logit\"), data = ejr)\n\nF4_direct_margins <- marginaleffects::marginaleffects(F4_direct, eps = 0.15)\n\n\nF4_trust <- lme4::lmer(Ztrust1 ~ Zeducation1 + Zincome1 +  (1|country_num), data = ejr)\n\nF4_multi <- lme4::lmer(Zmulti1 ~ Zeducation1 + Zincome1 +  (1|country_num), data = ejr)\n\n\nmodelsummary::modelsummary(list(\"Leave\" = F4_direct_margins, \n                                \"Trust in pol. est.\" = F4_trust, \n                                \"Support multiculturalism\" = F4_multi),\n                           coef_rename = c(\"Zeducation1\" = \"Education\",\n                                           \"Zincome1\" = \"Income\",\n                                           \"Zmulti1\" = \"Support for multiculturalism\",\n                                           \"Ztrust1\" = \"Trust in political establishment\"),\n                           statistic = NULL)\n\n\n\n\n   \n    Leave \n    Trust in pol. est. \n    Support multiculturalism \n  \n\n\n Education \n    −0.012 \n    0.064 \n    0.210 \n  \n\n Income \n    −0.012 \n    0.111 \n    0.074 \n  \n\n Support for multiculturalism \n    −0.075 \n     \n     \n  \n\n Trust in political establishment \n    −0.061 \n     \n     \n  \n\n (Intercept) \n     \n    −0.011 \n    0.008 \n  \n\n SD (Intercept country_num) \n     \n    0.372 \n    0.353 \n  \n\n SD (Observations) \n     \n    0.903 \n    0.888 \n  \n\n Num.Obs. \n    23850 \n    23923 \n    23865 \n  \n\n R2 Marg. \n    0.193 \n    0.022 \n    0.063 \n  \n\n R2 Cond. \n    0.280 \n    0.164 \n    0.191 \n  \n\n AIC \n    19642.0 \n    63101.9 \n    62184.1 \n  \n\n BIC \n    19690.5 \n    63142.3 \n    62224.5 \n  \n\n ICC \n    0.1 \n    0.1 \n    0.1 \n  \n\n RMSE \n    0.36 \n    0.90 \n    0.89 \n  \n\n\n\n\n\nCompare the results in our table to those reported in Ejrnæs and Jensen (2021)"
  }
]