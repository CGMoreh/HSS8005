[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "ReadingsSoftwareTrainingHelp\n\n\n\nStatistics textbooks\nThe course does not strictly follow the content of a textbook, but the expectation is that students will read as much as possible of the assigned chapters from the following books:\n\n\n\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and other stories. Cambridge: Cambridge University Press.  ROS\n\n\nFree to download PDF version from the book’s website: https://avehtari.github.io/ROS-Examples\n\n\n\n\n\n\n\nAlexander, Rohan. 2023. Telling Stories with Data. Chapman and Hall/CRC  TSD\n\n\nFree online book: https://tellingstorieswithdata.com\n\n\n\n\n\n\n\nGelman, A., and Hill, J. 2007. Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge: Cambridge University Press.  ARM\n\n\nNote: ROS is the expanded and updated version of Part 1 (and some of Part 3) of this book. While everyone in the free world eagerly awaits the publication of ROS’s multilevel counterpart, we’ll use ARM as a reference work for the theory underpinning multilevel modelling.  Not freely available. Access it in print or online via the NU library\n\n\n\n\n\nRelatively large portions of text will be assigned for reading in each week from these books, referring to them by their acronyms. Don’t worry if you cannot read all the textbook content assigned in any given week! Those for whom the method covered by the assigned readings is new, will be able to refer back to them throughout the semester and beyond, reading thoroughly and completing the applied exercises. Those already familiar to some extent with the methods, should nonetheless read the text as a narrative and will discover hidden gems that will spectacularly improve their understanding and ability to interpret their statistical results.\n\n\nApplication articles\nIn the IT labs we will practice applying methods by reproducing small bits of published research, using the data and (critically) the modelling approaches used by the authors. To fully understand the context of these data and the methods used, you must read the original journal articles and the available supplementary materials provided alongside. These readings will be listed under each week’s outline (still work in progress!).\nThe articles come from a variety of different fields, so expect them to push you outside your disciplinary comfort zone. The point is to see how methods have been used in practice and learn how to reproduce (and potentially improve) those analyses. This will then enable you to apply this knowledge to your own research questions.\nWhen selecting the articles, the aim was to strike a fine balance between (a) the simplicity of the methods employed, (b) data and analytical transparency, and (c) the strength of the analysis. So don’t take them as examples of all-rounds best practice, but examples of research that gets published while being self-confident enough to open itself up for public scrutiny. Aim for this in your own research!\n\n\nCoding\nThere will also be various readings relating more closely to the technicalities of coding in R and scientific writing, collaboration and communication in general. These readings will also be listed under each week’s outline as the semester progresses. The generic reading that students are advised to go through on their own is:\n\n\n\n\n\n\n\nWickham, Çetinkaya-Rundel and Grolemund. 2022. R for Data Science (2nd ed.)  R4DS\n\n\nFree online book: https://r4ds.hadley.nz/\n\n\n\n\n\n\nFurther recommended readings\nFinally, there will also be recommended readings listed under certain weeks that help place methods, statistics and probability theory in a broader frame. These are useful readings for everyone, regardless of whether you will be applying quantitative analysis in your research or future work.\n\n\n\n\nRequired software\nWe will use a number of open-source software for data analysis and scientific writing. You need to install these on your personal computers to be able to work away from campus:\n\n\n\n\nR\n(programming language)\nEssential\nR needs to be installed even if we will only use it via the RStudio interface.\nInstall the latest version from here\n\n\n\nRStudio\n(integrated development environment)\nEssential\nYou will need the free desktop version appropriate for your operating system. RStudio combines the R Console - the direct interface to R - with a number of other panels.\nInstall the latest version from here\n\n\n\nTidyverse\n(collection of R packages)\nEssential\nThe tidyverse is a collection of packages that make the R language easier to use by introducing a more consistent grammar. It provides functions that are particularly useful for data manipulation and visualisation. It is the most common ‘dialect’ used among social scientists.\nInstall from within RStudio by executing in the Console:\ninstall.packages(\"tidyverse\")\n\n\n\nQuarto\n(scientific publishing system)\nEssential\nWe will be using Quarto markdown documents (.qmd) throughout the course to document our data analysis. .qmd files extend the plain-text Markdown mark-up language (.md) to allow for data analysis code to be executed and results presented alongside the main text. This is an essential requirement for analytical transparency, reliability and reproducibility.The assignment will also be completed in .qmd.\nIncluded by default in the latest RStudio release; no need to install separately.\nYou can check your installation by executing in the RStudio Terminal :\nquarto check\n\n\n\nZotero\n(reference manager)\nRecommended\nIf you are not yet using a reference manager, I recommend giving Zotero a try. It will make your work much more efficient and it integrates (relatively well) with RMarkdown and Quarto using the the Better BibTeX add-on.\nInstall the latest version and add-ons from here\n\n\n\n\n\n\nStudents with no previous experience using R and/or RStudio are advised to complete the self-paced free online training course R for Social Scientists provided by Data Carpentry at https://datacarpentry.org/r-socialsci/\n\n\n\nThere are several ways to get help with  outside class. If you encounter an error message or are looking for a function to perform a specific task that we have not covered in class, you can do a Google search; for best results, use the https://rseek.org/ search engine, which limits the results to those relating to the  language.\nYou can also search for answers on Stack Overflow, which is a popular help and discussion website for programmers. You can also post a question there, but make sure to follow community standards and advice on how to ask a good question and how to provide a minimal reproducible example. You will need some experience using the site before being able to ask a good question, but it’s more than certain that any question you have at this stage has already been asked and answered somewhere. Make sure you do a comprehensive search with various prompts before thinking about asking your question.\nIncreasingly, large language model-based chatbots such as the (in)famous ChatGPT can also provide good answers. You can use them efficiently, but make sure to always test out the responses, in the overwhelming majority of the cases the advice they give is unreliable, at least at first try."
  },
  {
    "objectID": "plan.html",
    "href": "plan.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "Week\nTW\nDate\nTopic\nInfo\nNotes\nLecture\nLabs\nHandouts\n\n\n\n\n\n22\n27 January\nIntroduction  Module overview\n\n\n\n\n\n\n\nWeek 1\n22\n28 January\nTools  R, RStudio, Markdown, Quarto and other tools of the trade\n\n  \n\n  \n  \n\n\nWeek 2\n23\n04 February\nLines  Linear models and their limitations\n\n  \n  \n  \n  \n\n\nWeek 3\n24\n11 February\nCurves  Logistic regression and other generalised linear models\n\n  \n  \n  \n  \n\n\nWeek 4\n25\n18 February\nPaths  Graphical models and considerations for causal analysis\n\n  \n  \n  \n  \n\n\nWeek 5\n26\n25 February\nInteractions  Estimating, plotting and interpreting interaction effects\n\n  \n  \n  \n  \n\n\nWeek 6\n27\n03 March\nTemporalities  Panel, longitudinal and time-series analysis\n\n  \n  \n  \n  \n\n\nWeek 7\n28\n10 March\nHierarchies  Hierarchical data structures and multilevel modelling\n\n  \n  \n  \n  \n\n\nWeek 8\n29\n17 March\nDesigns  Simulation-based power analysis for study design\n\n  \n  \n  \n  \n\n\n\n29\n20 March\nConclusions  Sum up, divide, and conquer"
  },
  {
    "objectID": "materials/slides/test.html#not-outline-just-simple-dice",
    "href": "materials/slides/test.html#not-outline-just-simple-dice",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Not outline, just simple dice",
    "text": "Not outline, just simple dice\n\n\none\ntwo\nthree"
  },
  {
    "objectID": "materials/slides/test.html#numbered",
    "href": "materials/slides/test.html#numbered",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Numbered",
    "text": "Numbered\n\n\nGaming chance\nsecond topic\nThird topic\nForth topic"
  },
  {
    "objectID": "materials/slides/test.html#not-numbered",
    "href": "materials/slides/test.html#not-numbered",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Not numbered",
    "text": "Not numbered\n\n\nGaming chance\nsecond topic\nThird topic\nForth topic"
  },
  {
    "objectID": "materials/slides/test.html#numbered-small",
    "href": "materials/slides/test.html#numbered-small",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Numbered small",
    "text": "Numbered small\n\n\nGaming chance\nsecond topic\nThird topic\nForth topic"
  },
  {
    "objectID": "materials/slides/test.html#not-numbered-small",
    "href": "materials/slides/test.html#not-numbered-small",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Not numbered small",
    "text": "Not numbered small\n\n\nGaming chance\nsecond topic\nThird topic\nForth topic"
  },
  {
    "objectID": "materials/slides/test.html#just-text",
    "href": "materials/slides/test.html#just-text",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Just text",
    "text": "Just text\n\nSomething like a text here\n\nThis is my first line and it’s a very long line so that I can check how it looks like when it is printed on the slide and there are other lines below too\nThis is the second line\nAnd a third line here\n\nMore here\n\nFifth line\nSixth line"
  },
  {
    "objectID": "materials/slides/test.html#code",
    "href": "materials/slides/test.html#code",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Code",
    "text": "Code\n\n\na &lt;- rnorm(100, 4, 2)\nsummary(a)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.4391  3.0348  4.0027  4.1684  5.6485  9.2399 \n\n\n\n\nhist(a)"
  },
  {
    "objectID": "materials/slides/test.html#testing",
    "href": "materials/slides/test.html#testing",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Testing",
    "text": "Testing\n\n\nTesting\n\n\nhow\n\n\nfragments work in\n\n\nreality"
  },
  {
    "objectID": "materials/slides/test.html#testing-2",
    "href": "materials/slides/test.html#testing-2",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Testing 2",
    "text": "Testing 2\n\nTesting\n. . .\nHow\n. . .\nfragments work\n. . .\nreally"
  },
  {
    "objectID": "materials/slides/test.html#statistics",
    "href": "materials/slides/test.html#statistics",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Statistics",
    "text": "Statistics\n\nand the state"
  },
  {
    "objectID": "materials/slides/test.html#statistics-1",
    "href": "materials/slides/test.html#statistics-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Statistics",
    "text": "Statistics\nand probability\n\n\n\nStatistics as the mathematical science of using probability to describe uncertainty"
  },
  {
    "objectID": "materials/slides/test.html#gaming-chance",
    "href": "materials/slides/test.html#gaming-chance",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Gaming chance",
    "text": "Gaming chance\n\n\n\nWe may never know when humans started playing games of chance, but archaeological findings suggest it was a rather long time ago\nDuring the the First Dynasty in Egypt (c. 3500 B.C.) variants of a game involving astragali (small bones in the ankle of an animal) were already documented\nOne of the chief games may have been the simple one of throwing four astragali together and noting which sides fell uppermost"
  },
  {
    "objectID": "materials/slides/test.html#ālea-iacta-est",
    "href": "materials/slides/test.html#ālea-iacta-est",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Ālea iacta est",
    "text": "Ālea iacta est\n\n\n\nThe six-sided die we know today may have been obtained from the astragalus by grinding it down until it formed a rough cube\nDice became common in the Ptolemaic dynasty (300 to 30 B.C.)\nThere is evidence that dice were used for divination rites in this period - one carried the sacred symbols of Osiris, Horus, Isis, Nebhat, Hathor and Horhudet engraved on its six sides\nIn Roman times, rule by divination attained great proportions; Emperors Septimius Severus (Emperor A.D. 193-211) and Diocletian (Emperor AD. 284-305) were notorious for their reliance on the whims of the gods"
  },
  {
    "objectID": "materials/slides/test.html#fat-chance",
    "href": "materials/slides/test.html#fat-chance",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Fat chance",
    "text": "Fat chance\n\n\n\nHe threw four knucklebones on to the table and committed his hopes to the throw. If he threw well, particularly if he obtained the image of the goddess herself, no two showing the same number, he adored the goddess, and was in high hopes of gratifying his passion; if he threw badly, as usually happens, and got an unlucky combination, he called down imprecations on all Cnidos, and was as much overcome by grief as if he had suffered some personal loss.\n— Lucian of Samosata (c. 125 – 180), writing in his trademark satirical style about a young man who fell in love with Praxiteles’s Aphrodite of Knidos; cited in F. N. David (1955:8)"
  },
  {
    "objectID": "materials/slides/test.html#chance-with-limitations",
    "href": "materials/slides/test.html#chance-with-limitations",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Chance with limitations",
    "text": "Chance with limitations\n\n\n\nDice were sometimes faked. Sometimes numbers were left off or duplicated; hollow dice have been found dating from Roman time\nDice were also imperfect; a fair die was the exception rather than the rule\nExperiment by F. N. David using three dice from the British Museum:"
  },
  {
    "objectID": "materials/slides/test.html#exercise",
    "href": "materials/slides/test.html#exercise",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Exercise",
    "text": "Exercise\n\n\nWhich of the three dice (if any) would you call fair?\nWhat distribution of outcomes would you expect 204 fair dice rolls to produce prior to seeing any results?\nHow would you expect that distribution to change as the number of rolls progresses towards \\(\\infty\\)?\nWhat name would you give to that distribution?\nverv\nrever"
  },
  {
    "objectID": "materials/slides/test.html#from-chance-to-probability",
    "href": "materials/slides/test.html#from-chance-to-probability",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "From chance to probability\n",
    "text": "From chance to probability\n\n\n\n\nUntil 18th century people had mostly used probability to solve problems about dice throwing and other games of chance\nJacob (Jacques/James) Bernoulli (1654/1655-1705), a Swiss mathematician trained as a theologian and ordained as a minister of the Reformed church in Basel, began asking questions about probabilistic inference instead\nHis work focused on the mathematics of uncertainty - what he came to call stochastics (from the Greek word \\(στόχος\\) [stókhos] meaning to aim or “guess’)\n\nArs Conjectandi (The Art of Conjecturing) - published posthumously in 1713"
  },
  {
    "objectID": "materials/slides/test.html#inferential-questions",
    "href": "materials/slides/test.html#inferential-questions",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Inferential questions",
    "text": "Inferential questions\n\n\n\nSuppose you are presented with a large urn full of tiny white and black pebbles, in a ratio that’s unknown to you. You begin selecting pebbles from the urn and recording their colors, black or white. How do you use these results to make a guess about the ratio of pebble colors in the urn as a whole?\n\n\nBernoulli’s solution: if you take a large enough sample, you can be very sure, to within a small margin of absolute certainty, that the proportion of white pebbles you observe in the sample is close to the proportion of white pebbles in the urn.\nA first version of the Law of Large Numbers"
  },
  {
    "objectID": "materials/slides/test.html#large-numbers",
    "href": "materials/slides/test.html#large-numbers",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Large numbers",
    "text": "Large numbers\n\n\nBernoulli’s solution, more technically:  For any given \\(\\epsilon\\) &gt; 0 and any \\(s\\) &gt; 0, there is a sample size \\(n\\) such that, with \\(w\\) being the number of white pebbles counted in the sample and \\(f\\) being the true fraction of white pebbles in the urn, the probability of \\(w/n\\) falling between \\(f − \\epsilon\\) and \\(f + \\epsilon\\) is greater than \\(1 − s\\).\nthe fraction \\(w/n\\) is the ratio of white to total pebbles we observe in our sample\n\\(\\epsilon\\) (epsilon) captures the fact that we may not see the true urn ratio exactly thanks to random variation in the sample; larger samples help assure that we get closer to the true value, but uncertainty alwa ys remains\n\\(s\\) reflects just how sure we want to be; for example, set \\(s\\) = 0.01 and be 99% percent sure.\nmoral certainty as distinct from absolute certainty of the kind logical deduction provides"
  },
  {
    "objectID": "materials/slides/test.html#final-slides",
    "href": "materials/slides/test.html#final-slides",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Final slides",
    "text": "Final slides"
  },
  {
    "objectID": "materials/slides/test.html#references",
    "href": "materials/slides/test.html#references",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "materials/slides/hss8005_w2.html#video",
    "href": "materials/slides/hss8005_w2.html#video",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Video",
    "text": "Video"
  },
  {
    "objectID": "materials/slides-frame/index.html",
    "href": "materials/slides-frame/index.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\n\n\n\n\n \n\n\n \n\n\n\n\nWeek 1  Introduction\n\n\n \n\n\n\n\nWeek 1  Tools\n\n\n \n\n\n\n\nWeek 2  Lines\n\n\n \n\n\n\n\nWeek 3  Curves\n\n\n \n\n\n\n\nWeek 4  Paths\n\n\n \n\n\n\n\nWeek 5  Interactions\n\n\n \n\n\n\n\nWeek 6  Temporalities\n\n\n \n\n\n\n\nWeek 7  Hierarchies\n\n\n \n\n\n\n\nWeek 8  Designs\n\n\n \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materials/info/info_w08.html",
    "href": "materials/info/info_w08.html",
    "title": "Week 8  Designs",
    "section": "",
    "text": "We’ll practice some basic methods of computer simulation in R for statistical inference and for generating data that has some idealised characteristics. Such methods play an increasingly important role in computational statistics and are extremely useful for designing robust data collection and analysis plans. Of course, this topic also raises some much deeper existential issues. We have known ever since science-fiction author Philip K. Dick’s memorable “Metz address” of 1977 that our world is nothing but a complex computer simulation. We won’t be actively searching for empirical proof of this in class, but should we make a mistake in our code and end up in an infinite loop, we may be tempted to ponder whether if something like this can happen to our data, who says it couldn’t happen to us? If it happens and you’re afraid that stopping the process may cause the known universe to implode, you can watch Dick on YouTube while you wait.\n\nReadings\n\nROS: Chapters 5 (pp. 69-76) and 16 (pp. 291-310)\nTSD: TDS makes extensive use of simulation methods for various purposes at different stages of a research project (e.g. from data preparation through statistical inference to sharing results and data openly). A search on a keyword stub “simulat” can point you various sections of interest that are all worth reading.",
    "crumbs": [
      "Materials",
      "Week 8"
    ]
  },
  {
    "objectID": "materials/info/info_w06.html",
    "href": "materials/info/info_w06.html",
    "title": "Week 6  Temporalities",
    "section": "",
    "text": "We consider the “temporal” aspects of data and the opportunities (and challenges) they pose. The special kind of multilevel data structure we consider here involves repeated measurements on persons (or other units); measurements are therefore clustered within persons (or other units), and predictors can be available at the measurement or person level. Such datasets are often called panel or longitudinal. In settings where overall time trends are important, repeated measurement data are sometimes called time-series cross-sectional. Time-series cross-sectional data typically contain observations at regular time interval, and they commonly exhibit overall time patterns. In many such contexts one must consider how measurements cluster not only in the “temporal” variable but also in the “spatial” variable (e.g. country-year-level observations clustered within countries as well as years), with the potential for predictors at three levels (individual, temporal and spatial). We will consider such three (and higher)-level hierarchical analyses.\n\nReadings\nTextbook\n\nARM: Chapters 11 (pp. 237-249) and 12 (pp. 251-278)\n\nApplication\n\nMitchell, Jeffrey. 2021. “Social Trust and Anti-immigrant Attitudes in Europe: A Longitudinal Multi-Level Analysis.” Frontiers in Sociology 6 (April): 604884 - (online)\nKumove, Michael. 2024. “Take Five? Testing the Cultural and Experiential Theories of Generalised Trust Against Five Criteria.” Political Studies (online)\nDawson, Chris. 2019. “How Persistent Is Generalised Trust?” Sociology 53(3): 590–99. (online)\nBotzen, Katrin. 2015. “Are Joiners Trusters? A Panel Analysis of Participation and Generalized Trust.” Zeitschrift für Soziologie 44(5): 314–29. (online)\nSturgis, Patrick, Roger Patulny, Nick Allum, and Franz Buscha. 2012. Social Connectedness and Generalized Trust: A Longitudinal Perspective. Working Paper. ISER Working Paper Series. (online)",
    "crumbs": [
      "Materials",
      "Week 6"
    ]
  },
  {
    "objectID": "materials/info/info_w04.html",
    "href": "materials/info/info_w04.html",
    "title": "Week 4  Paths",
    "section": "",
    "text": "This week we ask some essential conceptual questions that can clarify various stated and unstated assumptions about our empirical data, theoretical questions and the models we aim to fit to them. We’ll explore the possibilities and challenges of asking causal questions of observational data, and we’ll think about ways to avoid what evolutionary anthropologist Richard McElreath calls ‘causal salad’. More generally, we explore ways of thinking about and dealing with the various biases that affect quantitative analyses.\n\nReadings\nStatistics\n\nCinelli, Carlos, Andrew Forney, and Judea Pearl. 2022. “A Crash Course in Good and Bad Controls.” Sociological Methods & Research https://journals.sagepub.com/doi/full/10.1177/00491241221099552\nLundberg, Ian, Rebecca Johnson, and Brandon M. Stewart. 2021. “What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory.” American Sociological Review 86(3): 532–65. https://doi.org/10.1177/00031224211004187\nROS: Chapters 18-20\n\nApplication\n\nGriffith, Gareth J., Tim T. Morris, Matthew J. Tudball, Annie Herbert, Giulia Mancano, Lindsey Pike, Gemma C. Sharp, Jonathan Sterne, Tom M. Palmer, George Davey Smith, Kate Tilling, Luisa Zuccolo, Neil M. Davies, and Gibran Hemani. 2020. “Collider Bias Undermines Our Understanding of COVID-19 Disease Risk and Severity.” Nature Communications 11(1): 5749. https://www.nature.com/articles/s41467-020-19478-2\nBreen, Richard. 2018. “Some Methodological Problems in the Study of Multigenerational Mobility.” European Sociological Review 34(6): 603–11. https://doi.org/10.1093/esr/jcy037",
    "crumbs": [
      "Materials",
      "Week 4"
    ]
  },
  {
    "objectID": "materials/info/info_w02.html",
    "href": "materials/info/info_w02.html",
    "title": "Week 2  Lines",
    "section": "",
    "text": "Description\nIn Edwin Abbott’s 1884 novella, the inhabitants of Flatland are geometric shapes living in a two-dimensional world, incapable of imagining the existence of higher dimensions. A sphere passing through the plain of their world is a fascinating but incomprehensible event: Flatlanders can only see a dot becoming a circle, increasing in circumference, then shrinking back in size and disappearing. There are, in this universe, worlds with even more limited views, like the one-dimensional Lineland and the zero-dimensional Pointland. Any attempt to expand the perspective of their inhabitant(s) is doomed to failure. But as in any good adventure story, a chosen Flatland native embarks on a journey of discovery and revelation - and ostracism and imprisonment. The story is interpreted as an allegorical criticism of Victorian-age social structure, but can equally describe the limitations of inhabiting uncritically a methodological world in which all data are ‘normal’ and all relationships are linear. Moving beyond linearity and acquiring the statistical intuition needed to think in higher dimensions and perceive more complex relationships is indeed a matter of practice-induced revelation. It’s unlikely that we will reach statistical nirvana in this short course, but we’ll attempt to build some more substantial structures upon the arid plains of linear regression. We start by looking around in the Flat-, Line- and Point-lands of quantitative analysis. Incorrigible procrastinators may want to check out a full-length computer animated film version of Flatland on YouTube. Others may be better served by this brief TED-Ed animation.\n\n\nReadings\nStatistics\n\nROS: Chapters 3, 4, 6-12\nTSD: Chapter 12 (“Linear models”)\n\nCoding\n\nTSD: Chapters 9 and 11\nR4DS: Chapters 11, 12\n\nApplication\n\nChapter 4 in Wilkinson, Richard G., and Kate Pickett. 2010. The Spirit Level: Why Greater Equality Makes Societies Stronger. New York: Bloomsbury Press.\nÖsterman, Marcus. 2021. ‘Can We Trust Education for Fostering Trust? Quasi-Experimental Evidence on the Effect of Education and Tracking on Social Trust’. Social Indicators Research 154(1):211–33 - (online)\nMitchell, Jeffrey. 2021. “Social Trust and Anti-immigrant Attitudes in Europe: A Longitudinal Multi-Level Analysis.” Frontiers in Sociology 6 (April): 604884 - (online)",
    "crumbs": [
      "Materials",
      "Week 2"
    ]
  },
  {
    "objectID": "materials/handouts/index.html",
    "href": "materials/handouts/index.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\nReading Time\n\n\n\n\n\n\nWeek 1 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 2 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 3 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 4 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 5 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 6 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 7 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 8 handout\n\n\n \n\n\n1 min\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data/index.html",
    "href": "data/index.html",
    "title": "Data documentation",
    "section": "",
    "text": "Datasets used throughout the course will be available for download from this page soon."
  },
  {
    "objectID": "assessment/index.html",
    "href": "assessment/index.html",
    "title": "Formative assessment",
    "section": "",
    "text": "Formative assessment\nStudents can submit their weekly Quarto worksheets with completed exercises by the end of each week for some brief formative feedback that they can build on. The worksheets should contain all the code and a maximum of 500 words of textual interpretation (not including any annotations added in code blocks to explain the code). The submission method and format is TBC; but we’ll take a light approach to things.\n\n\nSummative assessment\nStudents have the option to submit a collection of their (revised) worksheet exercises as a portfolio of work, with an added introduction, conclusion and framing.\nAlternatively, one/several of the covered data analysis methods can be applied to another dataset chosen by the student and developed into a comprehensive research report.\n\n   4,000-word data analysis portfolio/report (details on Canvas)\n   16:00 on 30th April 2025\n   Submit to Turnitin via Canvas\n\nMore detailed information is available on Canvas"
  },
  {
    "objectID": "data/data-documentation.html",
    "href": "data/data-documentation.html",
    "title": "Data documentation",
    "section": "",
    "text": "The datasets used in this course and available for download from the course website are the following:\n\n\n\nFile name\nOriginal name\nType\nVersion\nSurvey\nLinks\n\n\n\n\neb89.1\nZA6963_v1-0-0\n.dta\n.sav\n1.0.0\nEurobarometer; 89.1 (March 2018)\nSource\nQuestionnaire\nCodebook\n\n\ness9\nESS9e03_1\n.dta\n.sav\n3.1\nEuropean Social Survey; Integrated file, Round 9 (2018)\nSource\nQuestionnaire\nCodebook\n\n\nevs5\nZA7500_v4-0-0\n.dta\n.sav\n4.0.0\nEuropean Values Study; Wave 5 (2017-2020)\nSource\nQuestionnaire\nCodebook\n\n\nEUinUK2018\nEUinUK2018_Polish\n.dta\n-\nSurvey data collected by McGhee and Moreh (2018), ESRC Centre for Population Change\nSource\nQuestionnaire\nCodebook\n\n\nLaddLenz\nLaddLenz\n.dta\n-\nReplication data for Ladd and Lenz (2009), based on British Election Panel Study data\nSource\nQuestionnaire\nCodebook\n\n\nosterman\nReplication_data_ESS1-9_20201113\n.dta\n-\nReplication data for Österman (2020), based on European Social Survey Rounds 1-9 data\nSource\nQuestionnaire\nCodebook\n\n\n\nThe datasets can be read into R from \"https://cgmoreh.github.io/SSC7001M/data/FILE_NAME\" using an appropriate command from the haven package or other importing function.\n\n\n\n\n\nFile\n\n\nOriginal name\n\n\nType\n\n\nVersion\n\n\nOrigin\n\n\nAccess\n\n\n\n\n\n\nosterman\n\n\nReplication_data_ESS1-9_20201113\n\n\n.dta\n\n\nNA\n\n\nReplication data for Österman (2021), based on European Social Survey Rounds 1-9 data\n\n\nSource  Questionnaire  Codebook\n\n\n\n\nLaddLenz\n\n\nLaddLenz\n\n\n.dta\n\n\nNA\n\n\nReplication data for Ladd and Lenz (2009), based on British Election Panel Study data. Included in Hainmueller (2012)\n\n\nSource  Questionnaire  Codebook\n\n\n\n\n\n\n\n\n\nReferences\n\nHainmueller, Jens. 2012. “Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies.” Political Analysis 20 (1): 25–46. https://doi.org/10.1093/pan/mpr025.\n\n\nLadd, Jonathan McDonald, and Gabriel S. Lenz. 2009. “Exploiting a Rare Communication Shift to Document the Persuasive Power of the News Media.” American Journal of Political Science 53 (2): 394–410. https://doi.org/10.1111/j.1540-5907.2009.00377.x.\n\n\nÖsterman, Marcus. 2021. “Can We Trust Education for Fostering Trust? Quasi-experimental Evidence on the Effect of Education and Tracking on Social Trust.” Social Indicators Research 154 (1): 211–33. https://doi.org/10.1007/s11205-020-02529-y."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Quantitative analysis \n        ",
    "section": "",
    "text": "HSS8005 • Intermediate stream • 2024/2025 Winter/Spring\nNewcastle University (UK)\n        \n        \n            A continuation course in applied statistics and probability for the understanding of society and culture. It is aimed at an interdisciplinary postgraduate audience in the social sciences and humanities. Focusing on real-life examples from published research, the course emphasizes the scientific application of regression models, the practice of reproducible research workflows, and the communication of statistical results to diverse audiences. It prioritises understanding through modern computational techniques over mathematical abstraction.\n        \n    \n\n\n\n\n\n\nModule leader\n\n   Dr. Chris Moreh\n   HDB.4.106\n   chris.moreh at newcastle dot ac dot uk\n   Tutorial booker\n \n\n\n\nTeaching Assistants\n\n\n   Minki Sung\n\n\n\n\n\nTimetable\n\n   Tuesdays, Timetable Weeks 22-29\n    HDB.6.19 PGR Learning Lab\n   Lectures: 11:00-12:30\n   Labs: 13:00-14:30  \n\n\n\nAssessment\n\n   4,000-word data analysis portfolio/report (details on Canvas)\n   Submit by 16:00 on 30th April 2025\n   Submit to Turnitin via Canvas\n\n\n\n\n\n\nModule overview\nThis module is offered by School X - Researcher Education and Development to postgraduate students within the Faculty of Humanities and Social Sciences at Newcastle University. The module aims to provide a broad applied introduction to more advanced methods in quantitative analysis for students from various disciplinary backgrounds. See the module plan page for details about the methods covered. The course content consists of eight lectures (1.5 hours each) and eight IT labs (1.5 hours) . The course stands on three pillars: application, reproducibility and computation.\nApplication: we will work with real data originating from large-scale representative surveys or published research, with the aim of applying methods to concrete research scenarios. IT lab exercises will involve reproducing small bits of published research, using the data and (critically) the modelling approaches used by the authors. The aim is to see how methods have been used in practice in various disciplines and learn how to reproduce (and potentially improve) those analyses. This will then enable students to apply this knowledge to their own research questions. The data used in IT labs may be cleansed to allow focusing more on modelling tasks than on data wrangling, but exercises will address some of the more common data manipulation challenges and will cover essential functions. Data cleansing scripts will also be provided so that interested students can use them in their own work.\nReproducibility: developing a reproducible workflow that allows your future self or a reviewer of your work to understand your process of analysis and reproduce your results is essential for reliable and collaborative scientific research. We enforce the ideas and procedures of reproducible research both through replicating published research (see above) and in our practice (in the IT labs and the assignment). For an overview of why it’s important to develop a reproducible workflow early on in your research career and how to do it using (some) of the tools used in this module, read Chapter 3 of TSD (see Resources&gt;Readings). It’s also worth reading through Kieran Healy’s The Plain Person’s Guide to Plain Text Social Science, although there are now better software options than those discussed there. In this course, we will be using a suite of well-integrated free and open-source software to aid our reproducible workflow: the  statistical programming language and its currently most popular dialect – the {tidyverse} – via the  IDE for data analysis, and  for scientific writing and publishing (see Resources&gt;Software).\nComputation: the development of computational methods underpins the application of the most important statistical ideas of the past 50 years (see Andrew Gelman’s article on these developments here or an online workshop talk here; Richard McElreath’s great talk on Science as Amateur Software Development is well worth watching too). This module aims to develop basic computational skills that allow the application of complex statistical models to practical scientific problems without advanced mathematical knowledge, and which lay the foundation on which students can then pursue further learning and research in computational humanities and social sciences.\n\n\nPrerequisites\nTo benefit the most from this module, students are expected to have a foundational level of knowledge in quantitative methods: a good understanding of data types and distributions, familiarity with inferential statistics, and some exposure to linear regression. This is roughly equivalent to the content covered in a textbook such as OpenIntro Statistics (you can download it for free).\nThose who don’t feel completely up to date with linear regression but are determined to advance more quickly and read/practice beyond the compulsory material during weeks 1-3 are also encouraged to sign up.\nThose with a stronger background in multiple linear regression (e.g. students with undergraduate-level training in econometrics) will still benefit from weeks 1-3 as the approach we are taking is probably different from the one they are familiar with.\nNo previous knowledge of  or command-based statistical analysis software is needed. Gaining experience with using statistical software is part of the skills development aims of the module. However, it is not a general data science module, and the IT labs will cover a very limited number of functions (from both base , the tidyverse and other reliable user-written packages) that are most useful for tackling specific analysis tasks. Students are advised to complete some additional self-paced free online training in the use of the software, such as Data Carpentry’s R for Social Scientists, and to consult Wickham, Çetinkaya-Rundel and Grolemund’s R for Data Science) online book.\n\n\n\nThe course and the website were written and are maintained by Chris Moreh."
  },
  {
    "objectID": "materials/index.html",
    "href": "materials/index.html",
    "title": "Materials",
    "section": "",
    "text": "Materials for each week are available from the side menu. The table below outlines the weekly topics.\n\n\n\n\n\nWeekly topics\n\n\n\n\n\n\n\n\nWeek 1  Tools\n\n\nR, RStudio, Markdown, Quarto and other tools of the trade\n\n\n\n\nWeek 2  Lines\n\n\nLinear models and their limitations\n\n\n\n\nWeek 3  Curves\n\n\nLogistic regression and other generalised linear models\n\n\n\n\nWeek 4  Paths\n\n\nGraphical models and considerations for causal analysis\n\n\n\n\nWeek 5  Interactions\n\n\nEstimating, plotting and interpreting interaction effects\n\n\n\n\nWeek 6  Temporalities\n\n\nPanel, longitudinal and time-series analysis\n\n\n\n\nWeek 7  Hierarchies\n\n\nHierarchical data structures and multilevel modelling\n\n\n\n\nWeek 8  Designs\n\n\nSimulation-based power analysis for study design\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Materials",
      "Weekly materials"
    ]
  },
  {
    "objectID": "materials/info/info_w01.html",
    "href": "materials/info/info_w01.html",
    "title": "Week 1  Tools",
    "section": "",
    "text": "Description\nWe start the module with an applied introduction to the programming language R and the various tools that we will use to enhance its application to empirical research work in the social sciences. You will only gain a very basic and generic understanding of these software in this first week, but you will learn more throughout the semester, in the form of coding tasks associated with specific data analysis exercises.\n\n\nReadings\nTextbook readings\n\nR4DS: Chapters 1-10 (“Whole game”)\n\nFurther training\nFor further structured training in the use of R, RStudio and RMarkdown/Quarto, see the R for Social Scientists online course provided by Data Carpentry at https://datacarpentry.org/r-socialsci/\nJenny Bryan’s (RStudio/Posit) university-course-originated online book Stat545 is also a great resource for learning R and RStudio in more depth.\nFor a very different approach emphasising the value of learning ‘base’ R over the RStudio + {tidyverse} utility combo, see Norm Matloff’s course fasteR: Fast Lane to Learning R!.",
    "crumbs": [
      "Materials",
      "Week 1"
    ]
  },
  {
    "objectID": "materials/info/info_w03.html",
    "href": "materials/info/info_w03.html",
    "title": "Week 3  Curves",
    "section": "",
    "text": "Description\nIt wasn’t until the last quarter of the 20th century that a unified vision of statistical modelling emerged, allowing practitioners to see how the general linear model we have explored so far is only a specific case of a more general class of models. We could have had a fancy, memorable name for this class of models - as John Nelder, one of its inventors, acknowledged later in life (Senn 2003, 127) - but back then academics were not required to undertake marketing training on the tweetabilty-factor of the chosen names for their theories; so we ended up with “generalised linear models”. These models can be applied to explananda (“explained”, “response”, “outcome”, “dependent” etc. variables, our ys) whose possible values have certain constraints (such as being limited by a lower bound or constrained to discreet choices) that makes the parameters of the Gaussian (‘normal’) distribution inefficient in describing them. Instead, they follow some of the other “exponential distributions” (and not only the exponential: cf. Gelman, Hill, and Vehtari (2020, 264)), of which the Poisson, gamma, beta, binomial and multinomial are probably the most common in human and social sciences research. Their “generalised linear modelling” involves mapping them unto a linear model using a so-called “link function”. We will explore what all of this means in practice and how it can be applied to data that we are interested in most in our respective fields of study.\n\n\nReadings\nStatistics\n\nROS: Chapters 13-15\nConnelly, Roxanne, Vernon Gayle, and Paul S. Lambert. 2016. ‘Statistical Modelling of Key Variables in Social Survey Data Analysis’. Methodological Innovations 9:205979911663800. Library access\n\nCoding\n\nTSD: Chapter 13\n\nApplication\n\nWu, Cary. 2021. ‘Education and Social Trust in Global Perspective’. Sociological Perspectives 64(6):1166–86. Available here: Library access\nDingemans, Ellen, and Erik Van Ingen. 2015. ‘Does Religion Breed Trust? A Cross-National Study of the Effects of Religious Involvement, Religious Faith, and Religious Context on Social Trust’. Journal for the Scientific Study of Religion 54(4):739–55. Library access\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and other stories. Cambridge: Cambridge University Press. https://doi.org/10.1017/9781139161879.\n\n\nSenn, Stephen. 2003. “A Conversation with John Nelder.” Statistical Science 18 (1): 118–31. https://doi.org/10.1214/ss/1056397489.",
    "crumbs": [
      "Materials",
      "Week 3"
    ]
  },
  {
    "objectID": "materials/info/info_w05.html",
    "href": "materials/info/info_w05.html",
    "title": "Week 5  Interactions",
    "section": "",
    "text": "Description\nThis week we will return to some of the models we fit over the past two weeks and turn our attention to the right-hand side of the regression equations. We will explore interaction effects, which allow for the association between a predictor and an outcome to depend upon the value of another predictor. Understanding interaction effects - and the concept of conditioning more broadly - can help avoid serious misrepresentations and misunderstandings of our data. Some famous statistical “paradoxes” can highlight these dangers, and the lecture will build on these conceptual examples before moving on to questions of model-building. It is technically very simple to fit models with complex interactions, however, their interpretation can be very difficult. As with the logistic regression model we covered in Week 3, we will explore ways to present and visualise results from interaction models, which make their interpretation easier. Exploring interactions also allows us to begin thinking about causality and causal modelling, a topic that we will expand upon in Week 5.\n\n\nReadings\nStatistics\n\nROS: Chapters 10-12\n\nAdvanced statistics readings\n\nBrambor, T., W. R. Clark, and M. Golder. 2006. “Understanding Interaction Models: Improving Empirical Analyses.” Political Analysis 14(1): 63–82. https://doi.org/10.1093/pan/mpi014\nHainmueller, J., J. Mummolo, and Y. Q. Xu. 2019. “How Much Should We Trust Estimates from Multiplicative Interaction Models? Simple Tools to Improve Empirical Practice.” Political Analysis 27(2): 163–92 Library access here\nRohrer, Julia M., and Ruben C. Arslan. 2021. “Precise Answers to Vague Questions: Issues With Interactions.” Advances in Methods and Practices in Psychological Science 4(2): 25152459211007368 Library access here\n\nCoding\n\nTSD: Chapter 15\n\nApplication\n\nAkaeda, Naoki. 2023. “Trust and the Educational Gap in the Demand for Redistribution: Evidence from the World Values Survey and the European Value Study.” International Sociology 38(3): 290–310 Library access\nÖsterman, Marcus. 2021. ‘Can We Trust Education for Fostering Trust? Quasi-Experimental Evidence on the Effect of Education and Tracking on Social Trust’. Social Indicators Research 154(1):211–33 - (online)\nLadd, Jonathan McDonald, and Gabriel S. Lenz. 2009. ‘Exploiting a Rare Communication Shift to Document the Persuasive Power of the News Media’. American Journal of Political Science 53(2):394–410. doi: 10.1111/j.1540-5907.2009.00377.x.(published version should be accessible with university login; additional Appendix available here)",
    "crumbs": [
      "Materials",
      "Week 5"
    ]
  },
  {
    "objectID": "materials/info/info_w07.html",
    "href": "materials/info/info_w07.html",
    "title": "Week 7  Hierarchies",
    "section": "",
    "text": "Hierarchical data are ubiquitous in the social and human sciences (and beyond). In fact, almost all the application articles we have engaged with so far in previous labs modelled hierarchical data., and almost all modelled them explicitly as such, applying some multilevel modelling technique. In some cases the hierarchies themselves were of central theoretical importance and played a crucial role in the stated estimand (i.e. “the object of inquiry—(…) the precise quantity about which we marshal data to draw an inference” (see Lundberg, Johnson, and Stewart 2021:532). In others, taking into account the hierarchical nature of the data was meant to improve the precision of the main effect estimates. The importance of accounting for hierarchical dependencies in our models is emphasised by no one else more than Richard McElreath, who, in his important introductory-level book to Bayesian statistics, wants “to convince the reader of something that appears unreasonable: multilevel regression deserves to be the default form of regression” (McElreath 2020:15). According to him, “papers that do not use multilevel models should have to justify not using a multilevel approach”. In this session, we will learn how to think about and fit hierarchical models in R, and we’ll discuss some of the challenges of multilevel modelling and the possible justifications not to use them in certain contexts.\n\nReadings\nTextbook\n\nARM: Chapters 11 (pp. 237-249) and 12 (pp. 251-278)\nTSD: Chapter section 15.2\n\nApplication\n\nÖsterman, Marcus. 2021. ‘Can We Trust Education for Fostering Trust? Quasi-Experimental Evidence on the Effect of Education and Tracking on Social Trust’. Social Indicators Research 154(1):211–33 - (online)\nMitchell, Jeffrey. 2021. “Social Trust and Anti-immigrant Attitudes in Europe: A Longitudinal Multi-Level Analysis.” Frontiers in Sociology 6 (April): 604884 - (online)\nAkaeda, Naoki. 2023. “Trust and the Educational Gap in the Demand for Redistribution: Evidence from the World Values Survey and the European Value Study.” International Sociology 38(3): 290–310 Library access\nWu, Cary. 2021. ‘Education and Social Trust in Global Perspective’. Sociological Perspectives 64(6):1166–86. Available here: Library access\nDingemans, Ellen, and Erik Van Ingen. 2015. ‘Does Religion Breed Trust? A Cross-National Study of the Effects of Religious Involvement, Religious Faith, and Religious Context on Social Trust’. Journal for the Scientific Study of Religion 54(4):739–55. Library access\n\n\n\nFurther readings\n\nARM: Chapters 13 (pp. 279-299), 14 (pp. 301-323) and 15 (pp. 325-342)\n\n\n\n\n\n\nReferences\n\nLundberg, Ian, Rebecca Johnson, and Brandon M. Stewart. 2021. “What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory.” American Sociological Review 86(3):532–65. doi: 10.1177/00031224211004187.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. Second. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Materials",
      "Week 7"
    ]
  },
  {
    "objectID": "materials/slides/intro.html#meet-larry",
    "href": "materials/slides/intro.html#meet-larry",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Meet Larry…",
    "text": "Meet Larry…"
  },
  {
    "objectID": "materials/slides/intro.html#meet-larry-1",
    "href": "materials/slides/intro.html#meet-larry-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Meet Larry",
    "text": "Meet Larry"
  },
  {
    "objectID": "materials/slides/intro.html#deconstructing-larry",
    "href": "materials/slides/intro.html#deconstructing-larry",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Deconstructing Larry",
    "text": "Deconstructing Larry"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "References"
  }
]